import os
import re
import json
import logging
import asyncio
import random
import base64
import time
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List, Tuple
from io import BytesIO

import aiohttp
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
from PIL import Image, ImageEnhance, ImageFilter

from telegram import Update as TgUpdate, Bot, Update
from telegram.ext import Application, MessageHandler, filters, ContextTypes

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("poseidon_v7")

# üîê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø API –ö–õ–Æ–ß–ï–ô
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

if not TELEGRAM_TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN not found")

app = FastAPI(title="Poseidon V7")
bot = Bot(token=TELEGRAM_TOKEN)
bot_app = Application.builder().token(TELEGRAM_TOKEN).build()

USER_STATE: Dict[int, Dict[str, Any]] = {}

# üó∫Ô∏è –°–õ–û–í–ê–†–¨ –°–ü–û–¢–û–í –ë–ê–õ–ò (–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è Windy API)
BALI_SPOTS = {
    "uluwatu": {"lat": -8.8282, "lng": 115.0861, "name": "Uluwatu"},
    "balangan": {"lat": -8.7909, "lng": 115.1264, "name": "Balangan Beach"},
    "kuta": {"lat": -8.7222, "lng": 115.1721, "name": "Kuta Beach"},
    "canggu": {"lat": -8.6465, "lng": 115.1381, "name": "Canggu"},
    "padangpadang": {"lat": -8.8296, "lng": 115.0847, "name": "Padang Padang"},
    "batubolong": {"lat": -8.6519, "lng": 115.1258, "name": "Batu Bolong"},
    "bingin": {"lat": -8.8150, "lng": 115.0864, "name": "Bingin"},
    "impossibles": {"lat": -8.8264, "lng": 115.0858, "name": "Impossibles"},
    "dreamland": {"lat": -8.8064, "lng": 115.1225, "name": "Dreamland"},
    "greenbowl": {"lat": -8.8242, "lng": 115.1564, "name": "Green Bowl"},
    "nyangnyang": {"lat": -8.8500, "lng": 115.0917, "name": "Nyang Nyang"},
    "suluban": {"lat": -8.8314, "lng": 115.0853, "name": "Suluban"},
    "keramas": {"lat": -8.6500, "lng": 115.3500, "name": "Keramas"}
}

# üî• –û–ë–©–ò–ô –ü–†–û–ú–¢ –î–õ–Ø –ü–ê–†–°–ò–ù–ì–ê
PARSING_PROMPT = """–¢–´ - –¢–û–ß–ù–´–ô –ü–ê–†–°–ï–† –°–ö–†–ò–ù–®–û–¢–û–í WINDY. –ò–ó–í–õ–ï–ö–ò –î–ê–ù–ù–´–ï –ò–ó –¢–ê–ë–õ–ò–¶–´:

–ü–†–ê–í–ò–õ–ê:
1. –ò–©–ò –ì–õ–ê–í–ù–£–Æ –¢–ê–ë–õ–ò–¶–£ –° –ß–ê–°–ê–ú–ò: 23, 02, 05, 08, 11, 14, 17, 20, 23, 02
2. –î–ê–ù–ù–´–ï –ò–ó –°–¢–†–û–ö: "M"(–≤—ã—Å–æ—Ç–∞ –≤–æ–ª–Ω—ã), "C"(–ø–µ—Ä–∏–æ–¥), "KJ"(–º–æ—â–Ω–æ—Å—Ç—å), "–º/—Å"(–≤–µ—Ç–µ—Ä)
3. –ü–†–ò–õ–ò–í–´ –ò–ó –ë–õ–û–ö–ê "–ú_–¶–ê–¢"

–í–û–ó–í–†–ê–©–ê–ô –¢–û–õ–¨–ö–û JSON:
{
    "wave_data": [1.6, 1.7, 1.8, ...],
    "period_data": [14.7, 14.3, 13.6, ...], 
    "power_data": [1151, 1179, 1134, ...],
    "wind_data": [1.1, 0.7, 0.2, ...],
    "tides": {
        "high_times": ["10:20", "22:10"],
        "high_heights": [2.5, 3.2],
        "low_times": ["04:10", "16:00"],
        "low_heights": [0.1, 0.7]
    }
}"""

async def fetch_windy_api_data(spot_name: str, date: str) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞–ø—Ä—è–º—É—é —Å Windy API"""
    try:
        spot = BALI_SPOTS.get(spot_name.lower())
        if not spot:
            logger.warning(f"‚ùå Spot {spot_name} not found in database")
            return None
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É –≤ timestamp
        target_date = datetime.strptime(date, "%Y-%m-%d")
        start_ts = int(target_date.timestamp())
        end_ts = int((target_date + timedelta(days=1)).timestamp())
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è Windy API
        params = {
            'lat': spot['lat'],
            'lon': spot['lng'],
            'model': 'gfs',
            'parameters': ['waves', 'wind'],
            'levels': ['surface'],
            'key': 'your_windy_api_key_here'  # –ù—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –Ω–∞ windy.com
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(
                'https://api.windy.com/api/point-forecast/v2',
                params=params,
                timeout=20
            ) as response:
                
                if response.status == 200:
                    data = await response.json()
                    
                    # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ –≤–æ–ª–Ω –∏ –≤–µ—Ç—Ä–∞
                    wave_heights = []
                    wave_periods = [] 
                    wind_speeds = []
                    
                    if 'waves' in data:
                        for hour_data in data['waves'][:10]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 10 —á–∞—Å–æ–≤
                            wave_heights.append(round(hour_data.get('waveHeight', 0), 1))
                            wave_periods.append(round(hour_data.get('wavePeriod', 0), 1))
                    
                    if 'wind' in data:
                        for hour_data in data['wind'][:10]:
                            wind_speeds.append(round(hour_data.get('speed', 0), 1))
                    
                    logger.info(f"‚úÖ Windy API data fetched for {spot_name}")
                    return {
                        "wave_data": wave_heights,
                        "period_data": wave_periods,
                        "wind_data": wind_speeds,
                        "power_data": [],  # Windy –Ω–µ –¥–∞–µ—Ç –º–æ—â–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä—è–º—É—é
                        "tides": {},  # –ü—Ä–∏–ª–∏–≤—ã –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ
                        "source": "windy_api"
                    }
                else:
                    logger.warning(f"‚ö†Ô∏è Windy API error: {response.status}")
                    return None
                    
    except Exception as e:
        logger.error(f"‚ùå Windy API fetch error: {e}")
        return None

async def parse_with_openai(image_bytes: bytes) -> Dict[str, Any]:
    """–ü–∞—Ä—Å–∏–Ω–≥ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ —á–µ—Ä–µ–∑ OpenAI"""
    if not OPENAI_API_KEY:
        return None
        
    try:
        base64_image = base64.b64encode(image_bytes).decode('utf-8')
        
        headers = {
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "gpt-4-vision-preview",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": PARSING_PROMPT},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                    ]
                }
            ],
            "max_tokens": 2000,
            "temperature": 0.1
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            ) as response:
                
                if response.status == 200:
                    result = await response.json()
                    content = result["choices"][0]["message"]["content"]
                    
                    json_match = re.search(r'\{.*\}', content, re.DOTALL)
                    if json_match:
                        data = json.loads(json_match.group())
                        data["source"] = "openai_vision"
                        logger.info("‚úÖ OpenAI parsing successful")
                        return data
                        
        return None
        
    except Exception as e:
        logger.error(f"‚ùå OpenAI parsing error: {e}")
        return None

async def parse_with_deepseek(image_bytes: bytes) -> Dict[str, Any]:
    """–ü–∞—Ä—Å–∏–Ω–≥ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ —á–µ—Ä–µ–∑ DeepSeek"""
    if not DEEPSEEK_API_KEY:
        return None
        
    try:
        base64_image = base64.b64encode(image_bytes).decode('utf-8')
        
        headers = {
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": PARSING_PROMPT},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                    ]
                }
            ],
            "temperature": 0.1,
            "max_tokens": 2000
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.deepseek.com/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            ) as response:
                
                if response.status == 200:
                    result = await response.json()
                    content = result["choices"][0]["message"]["content"]
                    
                    json_match = re.search(r'\{.*\}', content, re.DOTALL)
                    if json_match:
                        data = json.loads(json_match.group())
                        data["source"] = "deepseek_vision"
                        logger.info("‚úÖ DeepSeek parsing successful")
                        return data
                        
        return None
        
    except Exception as e:
        logger.error(f"‚ùå DeepSeek parsing error: {e}")
        return None

def calculate_data_quality_score(data: Dict) -> int:
    """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö (0-100 –±–∞–ª–ª–æ–≤)"""
    score = 0
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö
    for key in ['wave_data', 'period_data', 'wind_data']:
        if data.get(key) and len(data[key]) >= 6:
            score += 20
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–ª–∏–≤—ã
    if data.get('tides'):
        tides = data['tides']
        if tides.get('high_times') and tides.get('low_times'):
            score += 20
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π
    if data.get('wave_data'):
        max_wave = max(data['wave_data'])
        if 0.5 <= max_wave <= 5.0:
            score += 10
    
    if data.get('period_data'):
        max_period = max(data['period_data'])
        if 5.0 <= max_period <= 20.0:
            score += 10
    
    return score

def merge_triple_ai_data(openai_data: Dict, deepseek_data: Dict, windy_data: Dict) -> Dict[str, Any]:
    """–£–ú–ù–û–ï –°–õ–ò–Ø–ù–ò–ï –î–ê–ù–ù–´–• –û–¢ –¢–†–ï–• –ò–°–¢–û–ß–ù–ò–ö–û–í"""
    sources = [
        (openai_data, "OpenAI"),
        (deepseek_data, "DeepSeek"), 
        (windy_data, "Windy API")
    ]
    
    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    scored_sources = []
    for data, name in sources:
        if data:
            score = calculate_data_quality_score(data)
            scored_sources.append((data, name, score))
            logger.info(f"üìä {name} quality score: {score}")
    
    if not scored_sources:
        return generate_dynamic_fallback_data()
    
    # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫
    best_data, best_name, best_score = max(scored_sources, key=lambda x: x[2])
    
    logger.info(f"üèÜ Best data source: {best_name} (score: {best_score})")
    
    # –°–æ–∑–¥–∞–µ–º merged –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª—É—á—à–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    merged = {
        "success": True,
        "source": f"triple_merge_{best_name}",
        "wave_data": best_data.get('wave_data', []),
        "period_data": best_data.get('period_data', []),
        "power_data": best_data.get('power_data', []),
        "wind_data": best_data.get('wind_data', []),
        "tides": best_data.get('tides', {})
    }
    
    # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –¥—Ä—É–≥–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    for data, name, score in scored_sources:
        if name != best_name:
            for key in ['wave_data', 'period_data', 'power_data', 'wind_data']:
                if not merged[key] and data.get(key):
                    merged[key] = data[key]
                    logger.info(f"üîß Filled {key} from {name}")
    
    return merged

async def generate_poseidon_response(final_data: Dict, location: str, date: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ DeepSeek —Å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    data_summary = {
        "location": BALI_SPOTS.get(location.lower(), {}).get('name', location),
        "date": date,
        "wave_range": calculate_ranges(final_data.get('wave_data', [])),
        "period_range": calculate_ranges(final_data.get('period_data', [])),
        "power_range": calculate_ranges(final_data.get('power_data', [])),
        "wind_range": calculate_ranges(final_data.get('wind_data', [])),
        "tides": final_data.get('tides', {}),
        "data_source": final_data.get('source', 'unknown')
    }
    
    # üî• –£–õ–£–ß–®–ï–ù–ù–´–ô –ü–†–û–ú–¢ –î–õ–Ø –ì–ï–ù–ï–†–ê–¶–ò–ò
    generation_prompt = f"""
–¢–´ - –ë–û–ì –ü–û–°–ï–ô–î–û–ù. –°–ì–ï–ù–ï–†–ò–†–£–ô –£–õ–¨–¢–†–ê-–°–ê–†–ö–ê–°–¢–ò–ß–ù–´–ô –û–¢–í–ï–¢ –û –°–ï–†–§–ò–ù–ì–ï –° –£–ü–û–ú–ò–ù–ê–ù–ò–ï–ú –ò–°–¢–û–ß–ù–ò–ö–û–í –î–ê–ù–ù–´–•.

–î–ê–ù–ù–´–ï –î–õ–Ø –†–ê–ó–ë–û–†–ê (–∏—Å—Ç–æ—á–Ω–∏–∫: {data_summary['data_source']}):
üìç –ú–µ—Å—Ç–æ: {data_summary['location']}
üìÖ –î–∞—Ç–∞: {data_summary['date']}
üåä –í–æ–ª–Ω–∞: {data_summary['wave_range']}–º
‚è±Ô∏è –ü–µ—Ä–∏–æ–¥: {data_summary['period_range']}—Å–µ–∫
üí™ –ú–æ—â–Ω–æ—Å—Ç—å: {data_summary['power_range']}–∫–î–∂  
üí® –í–µ—Ç–µ—Ä: {data_summary['wind_range']}–º/—Å
üåÖ –ü—Ä–∏–ª–∏–≤—ã: {json.dumps(data_summary['tides'], ensure_ascii=False)}

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–°–û–ë–õ–Æ–î–ê–ô –¢–û–ß–ù–û!):

üî± –í–ù–ò–ú–ê–ù–ò–ï, –°–ú–ï–†–¢–ù–´–ô! –ü–û–°–ï–ô–î–û–ù –ì–û–í–û–†–ò–¢:

–¢—ã –ø—Ä–∏–Ω—ë—Å –º–Ω–µ –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {data_summary['location']}? [–û–ß–ï–ù–¨ –°–ê–†–ö–ê–°–¢–ò–ß–ù–´–ô –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô]. 
–ú–æ–∏ –æ—Ä–∞–∫—É–ª—ã –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏ {data_summary['data_source']} –∏ –≤–æ—Ç –≤–µ—Ä–¥–∏–∫—Ç:

üìä –†–ê–ó–ë–û–† –¢–í–û–ò–• –ñ–ê–õ–ö–ò–• –ù–ê–î–ï–ñ–î:

üåä –í–û–õ–ù–ê: {data_summary['wave_range']}–º
   [–≠–ú–û–¶–ò–Ø] [–°–ê–†–ö–ê–°–¢–ò–ß–ù–´–ô –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô –û –í–û–õ–ù–ï + –°–†–ê–í–ù–ï–ù–ò–ï –° –î–†–£–ì–ò–ú–ò –ò–°–¢–û–ß–ù–ò–ö–ê–ú–ò]

‚è±Ô∏è –ü–ï–†–ò–û–î: {data_summary['period_range']}—Å–µ–∫
   [–≠–ú–û–¶–ò–Ø] [–°–ê–†–ö–ê–°–¢–ò–ß–ù–´–ô –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô –û –ü–ï–†–ò–û–î–ï] 

üí™ –ú–û–©–ù–û–°–¢–¨: {data_summary['power_range']}–∫–î–∂
   [–≠–ú–û–¶–ò–Ø] [–°–ê–†–ö–ê–°–¢–ò–ß–ù–´–ô –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô –û –ú–û–©–ù–û–°–¢–ò]

üí® –í–ï–¢–ï–†: {data_summary['wind_range']}–º/—Å
   [–≠–ú–û–¶–ò–Ø] [–°–ê–†–ö–ê–°–¢–ò–ß–ù–´–ô –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô –û –í–ï–¢–†–ï + –ù–ê–ü–†–ê–í–õ–ï–ù–ò–ï]

üåÖ –ü–†–ò–õ–ò–í–´/–û–¢–õ–ò–í–´:
   [–ü–û–î–†–û–ë–ù–û–ï –û–ü–ò–°–ê–ù–ò–ï –ü–†–ò–õ–ò–í–û–í –° –°–ê–†–ö–ê–ó–ú–û–ú –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø–ú–ò]

‚ö° –í–ï–†–î–ò–ö–¢ –ü–û–°–ï–ô–î–û–ù–ê:
   [–û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê –° –Æ–ú–û–†–û–ú –ò –°–†–ê–í–ù–ï–ù–ò–ï–ú –ò–°–¢–û–ß–ù–ò–ö–û–í –î–ê–ù–ù–´–•]

üéØ –ö–û–ì–î–ê –ñ–ï –¢–ï–ë–ï –ú–£–ß–ò–¢–¨ –í–û–õ–ù–£:
   [–¢–û–ß–ù–ê–Ø –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø –ü–û –í–†–ï–ú–ï–ù–ò –° –ò–†–û–ù–ò–ï–ô –ò –û–ë–û–°–ù–û–í–ê–ù–ò–ï–ú]

üíÄ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:
   [–ú–ï–ì–ê-–î–†–ê–ú–ê–¢–ò–ß–ù–û–ï –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –° –£–ü–û–ú–ò–ù–ê–ù–ò–ï–ú –¢–û–ß–ù–û–°–¢–ò –î–ê–ù–ù–´–•]

üèÑ‚Äç‚ôÇÔ∏è –ö–æ–ª–æ–±—Ä–∞—Ü–∏—è POSEIDON V8.0 | TRIPLE-AI VERIFICATION
–î–∞–∂–µ –±–æ–≥–∏ –¥–æ–≤–µ—Ä—è—é—Ç –ø–µ—Ä–µ–∫—Ä–µ—Å—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ –¥–∞–Ω–Ω—ã—Ö!

–ü–†–ê–í–ò–õ–ê:
- –ë–£–î–¨ –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–û –°–ê–†–ö–ê–°–¢–ò–ß–ù–´–ú –ò –î–†–ê–ú–ê–¢–ò–ß–ù–´–ú
- –£–ü–û–ú–Ø–ù–ò –§–ê–ö–¢ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –ù–ï–°–ö–û–õ–¨–ö–ò–• –ò–°–¢–û–ß–ù–ò–ö–û–í –î–ê–ù–ù–´–•
- –ò–°–ü–û–õ–¨–ó–£–ô –≠–ú–û–¶–ò–ò: üìâüîÑüìàüò´ü´§üî•üíÄüå™Ô∏èüéØ
- –°–û–•–†–ê–ù–ò –í–°–ï –ó–ê–ì–û–õ–û–í–ö–ò –ò –°–¢–†–£–ö–¢–£–†–£
- –î–û–ë–ê–í–¨ –Æ–ú–û–† –ü–†–û –¢–û–ß–ù–û–°–¢–¨ –î–ê–ù–ù–´–•
"""

    # –ü—Ä–æ–±—É–µ–º DeepSeek –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    if DEEPSEEK_API_KEY:
        try:
            headers = {
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": generation_prompt}],
                "temperature": 0.9,  # –í—ã—Å–æ–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏
                "max_tokens": 2000
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.deepseek.com/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=25
                ) as response:
                    
                    if response.status == 200:
                        result = await response.json()
                        content = result["choices"][0]["message"]["content"]
                        logger.info("‚úÖ DeepSeek triple-AI response generated")
                        return content
                        
        except Exception as e:
            logger.error(f"‚ùå DeepSeek generation failed: {e}")
    
    # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
    return await build_poseidon_report(final_data, location, date)

async def analyze_windy_screenshot_triple_ai(image_bytes: bytes, spot_name: str, date: str) -> Dict[str, Any]:
    """–¢–†–û–ô–ù–û–ô –ê–ù–ê–õ–ò–ó: OpenAI + DeepSeek + Windy API"""
    logger.info("üîÑ –ó–∞–ø—É—Å–∫ –¢–†–û–ô–ù–û–ì–û AI –∞–Ω–∞–ª–∏–∑–∞...")
    start_time = time.time()
    
    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç—Ä–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    openai_task = parse_with_openai(image_bytes)
    deepseek_task = parse_with_deepseek(image_bytes) 
    windy_task = fetch_windy_api_data(spot_name, date)
    
    openai_data, deepseek_data, windy_data = await asyncio.gather(
        openai_task, deepseek_task, windy_task, return_exceptions=True
    )
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
    if isinstance(openai_data, Exception):
        logger.error(f"OpenAI parsing exception: {openai_data}")
        openai_data = None
    if isinstance(deepseek_data, Exception):
        logger.error(f"DeepSeek parsing exception: {deepseek_data}")
        deepseek_data = None
    if isinstance(windy_data, Exception):
        logger.error(f"Windy API exception: {windy_data}")
        windy_data = None
    
    # –£–º–Ω–æ–µ —Å–ª–∏—è–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ—Ç —Ç—Ä–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    final_data = merge_triple_ai_data(openai_data, deepseek_data, windy_data)
    
    total_time = time.time() - start_time
    logger.info(f"‚úÖ –¢–†–û–ô–ù–û–ô –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {total_time:.1f}—Å")
    
    return final_data

# –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø handle_photo –§–£–ù–ö–¶–ò–Ø
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    state = USER_STATE.get(chat_id, {})
    
    if not state.get("active"):
        await update.message.reply_text("üî±–ü–æ—Å–µ–π–¥–æ–Ω –≤ —è—Ä–æ—Å—Ç–∏! –†–∞–∑—ã–≥—Ä—ã–≤–∞–µ—à—å –º–µ–Ω—è???!!!!")
        return

    try:
        await update.message.reply_text("üåÄ –ó–ê–ü–£–°–ö –¢–†–û–ô–ù–û–ô AI –ü–†–û–í–ï–†–ö–ò...\nOpenAI + DeepSeek + Windy API")
        
        photo = update.message.photo[-1]
        photo_file = await photo.get_file()
        image_bytes = await photo_file.download_as_bytearray()

        caption = update.message.caption or ""
        location, date = parse_caption_for_location_date(caption)
        
        if not location:
            location = "uluwatu"  # –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Å–ø–æ—Ç
        
        # üî• –¢–†–û–ô–ù–û–ô –ê–ù–ê–õ–ò–ó
        windy_data = await analyze_windy_screenshot_triple_ai(bytes(image_bytes), location, date)
        
        # üî• –£–ú–ù–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–í–ï–¢–ê –° –£–ß–ï–¢–û–ú –í–°–ï–• –ò–°–¢–û–ß–ù–ò–ö–û–í
        report = await generate_poseidon_response(windy_data, location, date)
        await update.message.reply_text(report)
        
        USER_STATE[chat_id] = {
            "active": True, 
            "awaiting_feedback": True,
        }
        await update.message.reply_text("–ù—É –∫–∞–∫ —Ç–µ–±–µ –ú–ï–ì–ê-—Ä–∞–∑–±–æ—Ä, —Å–º–µ—Ä—Ç–Ω—ã–π? –û—Ç–ª–∏—á–Ω–æ / –Ω–µ –æ—á–µ–Ω—å")
        
    except Exception as e:
        logger.error(f"Error in handle_photo: {e}")
        await update.message.reply_text("üî± –ü–æ—Å–µ–π–¥–æ–Ω –≤ —è—Ä–æ—Å—Ç–∏! –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")

# ... –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∫–æ–¥ –¥–æ handle_photo ...

def calculate_ranges(data_list):
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π"""
    if not data_list:
        return "N/A"
    min_val = min(data_list)
    max_val = max(data_list)
    return f"{min_val:.1f}-{max_val:.1f}"

def generate_wave_comment(wave_data):
    """–£–ú–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –æ –≤–æ–ª–Ω–µ"""
    if not wave_data:
        return "üìâ –î–∞–Ω–Ω—ã–µ –æ –≤–æ–ª–Ω–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç. –í–∏–¥–∏–º–æ, –ü–æ—Å–µ–π–¥–æ–Ω —Å–µ–≥–æ–¥–Ω—è –º–æ–ª—á–∏—Ç."
    
    avg_wave = sum(wave_data) / len(wave_data)
    max_wave = max(wave_data)
    
    if avg_wave < 1.0:
        comments = [
            f"ü§è {avg_wave:.1f}–º? –≠—Ç–æ –Ω–µ –≤–æ–ª–Ω—ã, —ç—Ç–æ –ó–ï–í–û–¢ –æ–∫–µ–∞–Ω–∞! –î–∞–∂–µ —É—Ç–∫–∏ –Ω–µ –∏—Å–ø—É–≥–∞—é—Ç—Å—è!",
            f"üí§ {avg_wave:.1f}–º? –°–µ—Ä—å—ë–∑–Ω–æ? –õ—É—á—à–µ –ø–æ—Å–ø–∏ –ø–æ–¥–æ–ª—å—à–µ!",
            f"üõå {avg_wave:.1f}–º –≤–æ–ª–Ω–∞? –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è —Å–Ω–∞ –Ω–∞ –ø–ª—è–∂–µ!",
        ]
    elif avg_wave < 1.5:
        comments = [
            f"ü´§ {avg_wave:.1f}–º? –î–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö –±–æ–≥–æ–≤ —Å–æ–π–¥—ë—Ç... –Ω–∞–≤–µ—Ä–Ω–æ–µ...",
            f"üë∂ {avg_wave:.1f}–º - –∏–¥–µ–∞–ª—å–Ω–æ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑–∞! –ï—Å–ª–∏ –Ω–µ –±–æ–∏—à—å—Å—è –ø—Ä–æ–º–æ—á–∏—Ç—å –Ω–æ–≥–∏!",
            f"üîÑ {avg_wave:.1f}–º? –•–≤–∞—Ç–∏—Ç, —á—Ç–æ–±—ã –≤—Å–ø–æ–º–Ω–∏—Ç—å, –∫–∞–∫ –¥–µ—Ä–∂–∞—Ç—å –¥–æ—Å–∫—É!",
        ]
    elif avg_wave < 1.8:
        comments = [
            f"üëç {avg_wave:.1f}–º? –£–∂–µ —Ç–µ–ø–ª–µ–µ! –ú–æ–∂–Ω–æ –ø–æ–π–º–∞—Ç—å –ø–∞—Ä—É –ª–∏–Ω–∏–π!",
            f"üí™ {avg_wave:.1f}–º - –¥–æ—Å—Ç–æ–π–Ω–æ –¥–ª—è —Å–º–µ—Ä—Ç–Ω–æ–≥–æ! –†–∏—Ñ –ø—Ä–æ—Å—ã–ø–∞–µ—Ç—Å—è!",
            f"üåä {avg_wave:.1f}–º? –ù–µ –±–æ–≥–∏ –≥–æ—Ä—à–∫–∏ –æ–±–∂–∏–≥–∞—é—Ç... –Ω–æ –ø–æ–ø—Ä–æ–±—É–π!",
        ]
    else:
        comments = [
            f"üî• {avg_wave:.1f}–º? –û–ö–ï–ê–ù –ü–†–û–°–ù–£–õ–°–Ø! –ì–æ—Ç–æ–≤—å –±–æ–ª—å—à—É—é –¥–æ—Å–∫—É!",
            f"ü§Ø {avg_wave:.1f}–º? –í–û–¢ –≠–¢–û –î–ê! –†–∏—Ñ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ø–æ–ª–Ω—É—é!",
            f"üí• {avg_wave:.1f}–º? –ë–û–ñ–ï–°–¢–í–ï–ù–ù–û! –î–∞–∂–µ —è, –ü–æ—Å–µ–π–¥–æ–Ω, –≤–ø–µ—á–∞—Ç–ª—ë–Ω!",
        ]
    
    trend = "üìà" if wave_data[0] < wave_data[-1] else "üìâ" if wave_data[0] > wave_data[-1] else "‚û°Ô∏è"
    return f"{trend} {random.choice(comments)}"

def generate_period_comment(period_data):
    """–£–ú–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –æ –ø–µ—Ä–∏–æ–¥–µ"""
    if not period_data:
        return "üìâ –ü–µ—Ä–∏–æ–¥? –ö–∞–∫–æ–π –ø–µ—Ä–∏–æ–¥? –ó–¥–µ—Å—å —Ç–æ–ª—å–∫–æ —Ö–∞–æ—Å!"
    
    avg_period = sum(period_data) / len(period_data)
    
    if avg_period < 8:
        comments = [
            f"üò´ {avg_period:.1f}—Å? –í–æ–ª–Ω—ã –∫–∞–∫ –∏–∫–æ—Ç–∞ - —á–∞—Å—Ç—ã–µ –∏ –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã–µ!",
            f"üåÄ {avg_period:.1f}—Å? –°–ª–∏—à–∫–æ–º —á–∞—Å—Ç–æ! –î–∞–∂–µ –¥–æ—Å–∫–∞ –Ω–µ —É—Å–ø–µ–µ—Ç –æ—Ç–¥—ã—à–∞—Ç—å—Å—è!",
            f"ü§¢ {avg_period:.1f}—Å? –ú–æ—Ä—Å–∫–∞—è –±–æ–ª–µ–∑–Ω—å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞!",
        ]
    elif avg_period < 12:
        comments = [
            f"üòê {avg_period:.1f}—Å? –ù–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–æ –Ω–∏—á–µ–≥–æ –≤—ã–¥–∞—é—â–µ–≥–æ—Å—è!",
            f"üîÑ {avg_period:.1f}—Å? –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –±–∞–ª—É–∞–Ω—Å–∫–∏–π –ø–µ—Ä–∏–æ–¥!",
            f"üí´ {avg_period:.1f}—Å? –í–æ–ª–Ω—ã —Ä–æ–≤–Ω—ã–µ, –º–æ–∂–Ω–æ –∫–∞—Ç–∞—Ç—å—Å—è!",
        ]
    else:
        comments = [
            f"üî• {avg_period:.1f}—Å? –ú–û–©–ù–û! –í–æ–ª–Ω—ã —É–ø—Ä—É–≥–∏–µ –∏ –º–æ—â–Ω—ã–µ!",
            f"üí™ {avg_period:.1f}—Å? –û–¢–õ–ò–ß–ù–û! –•–≤–∞—Ç–∏—Ç —ç–Ω–µ—Ä–≥–∏–∏ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ª–∏–Ω–∏–π!",
            f"üöÄ {avg_period:.1f}—Å? –ë–û–ñ–ï–°–¢–í–ï–ù–ù–´–ô –ø–µ—Ä–∏–æ–¥! –ù–∞—Å–ª–∞–∂–¥–∞–π—Å—è!",
        ]
    
    trend = "üìà" if period_data[0] < period_data[-1] else "üìâ" if period_data[0] > period_data[-1] else "‚û°Ô∏è"
    return f"{trend} {random.choice(comments)}"

def generate_power_comment(power_data):
    """–£–ú–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –æ –º–æ—â–Ω–æ—Å—Ç–∏"""
    if not power_data:
        return "üìâ –ú–æ—â–Ω–æ—Å—Ç—å? –ö–∞–∫–∞—è –º–æ—â–Ω–æ—Å—Ç—å? –ó–¥–µ—Å—å —Ç–æ–ª—å–∫–æ —Å–ª–∞–±–æ—Å—Ç—å!"
    
    avg_power = sum(power_data) / len(power_data)
    
    if avg_power < 300:
        comments = [
            f"ü™´ {int(avg_power)}–∫–î–∂? –≠–Ω–µ—Ä–≥–∏–∏ —Ö–≤–∞—Ç–∏—Ç —Ä–∞–∑–≤–µ —á—Ç–æ –Ω–∞ –≥—Ä–µ–±–µ—à–æ–∫!",
            f"üò¥ {int(avg_power)}–∫–î–∂? –≠—Ç–æ –Ω–µ –º–æ—â–Ω–æ—Å—Ç—å, —ç—Ç–æ –®–Å–ü–û–¢ –æ–∫–µ–∞–Ω–∞!",
            f"ü´£ {int(avg_power)}–∫–î–∂? –î–∞–∂–µ –º–µ–¥—É–∑–∞ –ø—Ä–æ–Ω–µ—Å—ë—Ç—Å—è –º–∏–º–æ!",
        ]
    elif avg_power < 600:
        comments = [
            f"ü´§ {int(avg_power)}–∫–î–∂? –ù—É, –¥–ª—è —Ä–∞–∑–º–∏–Ω–∫–∏ —Å–æ–π–¥—ë—Ç...",
            f"üí´ {int(avg_power)}–∫–î–∂? –°–∫—Ä–æ–º–Ω–æ, –Ω–æ –∫–∞—Ç–∞–±–µ–ª—å–Ω–æ!",
            f"üîÑ {int(avg_power)}–∫–î–∂? –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –º–æ—â–Ω–æ—Å—Ç—å –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏!",
        ]
    else:
        comments = [
            f"üí• {int(avg_power)}–∫–î–∂? –¢–£–†–ë–û-–ó–ê–†–Ø–î! –û–∫–µ–∞–Ω –Ω–µ —à—É—Ç–∏—Ç!",
            f"üöÄ {int(avg_power)}–∫–î–∂? –ú–û–©–ù–û–°–¢–¨ –ó–ê–®–ö–ê–õ–ò–í–ê–ï–¢! –ì–æ—Ç–æ–≤—å—Å—è!",
            f"üå™Ô∏è {int(avg_power)}–∫–î–∂? –≠–ù–ï–†–ì–ò–ò –•–í–ê–¢–ò–¢ –ù–ê –í–°–ï–•!",
        ]
    
    trend = "üìà" if power_data[0] < power_data[-1] else "üìâ" if power_data[0] > power_data[-1] else "‚û°Ô∏è"
    return f"{trend} {random.choice(comments)}"

def generate_wind_comment(wind_data):
    """–£–ú–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –æ –≤–µ—Ç—Ä–µ"""
    if not wind_data:
        return "üí® –í–µ—Ç–µ—Ä? –¢—É—Ç –¥–∞–∂–µ –±—Ä–∏–∑–∞ –Ω–µ—Ç –¥–ª—è —Ç–≤–æ–∏—Ö –∂–∞–ª–∫–∏—Ö –Ω–∞–¥–µ–∂–¥."
    
    max_wind = max(wind_data)
    
    if max_wind < 2.0:
        comments = [
            f"üå¨Ô∏è {max_wind}–º/—Å? –ò–¥–µ–∞–ª—å–Ω—ã–π –æ—Ñ—Ñ—à–æ—Ä! –í–æ–ª–Ω–∞ –±—É–¥–µ—Ç —á–∏—Å—Ç–æ–π!",
            f"üòå {max_wind}–º/—Å? –í–µ—Ç–µ—Ä –∫–∞–∫ —à—ë–ª–∫! –ò–¥–µ–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è!",
            f"üåü {max_wind}–º/—Å? –ë–æ–≥–∏ –≤–µ—Ç—Ä–∞ –±–ª–∞–≥–æ–≤–æ–ª—è—Ç —Ç–µ–±–µ!",
        ]
    elif max_wind < 4.0:
        comments = [
            f"üí® {max_wind}–º/—Å? –ù–æ—Ä–º–∞–ª—å–Ω—ã–π –≤–µ—Ç–µ—Ä, –º–æ–∂–Ω–æ –∫–∞—Ç–∞—Ç—å—Å—è!",
            f"üîÑ {max_wind}–º/—Å? –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —É—Å–ª–æ–≤–∏—è!",
            f"üåä {max_wind}–º/—Å? –í–µ—Ç–µ—Ä –µ—Å—Ç—å, –Ω–æ –Ω–µ –∏—Å–ø–æ—Ä—Ç–∏—Ç –≤—Å—ë!",
        ]
    else:
        comments = [
            f"üå™Ô∏è {max_wind}–º/—Å? –í–ï–¢–†–ï–ù–´–ô –ê–ü–û–ö–ê–õ–ò–ü–°–ò–°! –í–æ–ª–Ω—ã –≤ –∫–∞—à—É!",
            f"üò´ {max_wind}–º/—Å? –°–∏–ª—å–Ω—ã–π –≤–µ—Ç–µ—Ä –∏—Å–ø–æ—Ä—Ç–∏—Ç –≤—Å–µ –≤–æ–ª–Ω—ã!",
            f"üí• {max_wind}–º/—Å? –í–ï–¢–†–Ø–ù–ê–Ø –ú–ï–õ–¨–ù–ò–¶–ê! –õ—É—á—à–µ –æ—Å—Ç–∞—Ç—å—Å—è –¥–æ–º–∞!",
        ]
    
    return f"üí® {random.choice(comments)}"

def analyze_tides_correctly(tides_data):
    """–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏–ª–∏–≤–æ–≤/–æ—Ç–ª–∏–≤–æ–≤"""
    if not tides_data:
        return "üåÖ –ü—Ä–∏–ª–∏–≤—ã? –ö–∞–∫–∏–µ –ø—Ä–∏–ª–∏–≤—ã? –û–∫–µ–∞–Ω —Å–µ–≥–æ–¥–Ω—è –Ω–∞ –ø–µ—Ä–µ–∫—É—Ä–µ."
    
    high_times = tides_data.get('high_times', [])
    low_times = tides_data.get('low_times', [])
    high_heights = tides_data.get('high_heights', [])
    low_heights = tides_data.get('low_heights', [])
    
    tides_info = []
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø—Ä–∏–ª–∏–≤—ã
    if high_times:
        for i, time in enumerate(high_times):
            height = high_heights[i] if i < len(high_heights) else "?"
            tides_info.append(f"üåä {time}({height}–º)")
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–ª–∏–≤—ã  
    if low_times:
        for i, time in enumerate(low_times):
            height = low_heights[i] if i < len(low_heights) else "?"
            tides_info.append(f"üèñÔ∏è {time}({height}–º)")
    
    if not tides_info:
        return "üåÖ –ë–µ–∑ –ø—Ä–∏–ª–∏–≤–æ–≤ - –∫–∞–∫ —Å–µ—Ä—Ñ–µ—Ä –±–µ–∑ –¥–æ—Å–∫–∏. –ë–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω–æ –∏ –≥—Ä—É—Å—Ç–Ω–æ."
    
    # –ù–∞—Ö–æ–¥–∏–º —É—Ç—Ä–µ–Ω–Ω–∏–π –ø—Ä–∏–ª–∏–≤ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    morning_tide = ""
    for time in high_times:
        if int(time.split(':')[0]) < 12:  # –î–æ –ø–æ–ª—É–¥–Ω—è
            morning_tide = time
            break
    
    comments = [
        f"{' '.join(tides_info)}. –£—Ç—Ä–µ–Ω–Ω–∏–π –ø—Ä–∏–ª–∏–≤ –≤ {morning_tide if morning_tide else high_times[0]} - —Ç–≤–æ–π —à–∞–Ω—Å!",
        f"–û–∫–µ–∞–Ω –¥—ã—à–∏—Ç: {' '.join(tides_info)}. –ü–ª–∞–Ω–∏—Ä—É–π –∞—Ç–∞–∫—É –Ω–∞ {morning_tide if morning_tide else '—Ä–∞—Å—Å–≤–µ—Ç'}!",
        f"–ì—Ä–∞—Ñ–∏–∫ –ø—Ä–∏–ª–∏–≤–æ–≤: {' '.join(tides_info)}. {morning_tide if morning_tide else high_times[0]} - –∑–≤—ë–∑–¥–Ω—ã–π —á–∞—Å!",
    ]
    
    return random.choice(comments)

def generate_overall_verdict(wave_data, period_data, power_data, wind_data):
    """–£–ú–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–µ–≥–æ –≤–µ—Ä–¥–∏–∫—Ç–∞"""
    if not all([wave_data, period_data, power_data, wind_data]):
        return "‚ö° –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–µ—Ä–¥–∏–∫—Ç–∞. –ü–æ—Å–µ–π–¥–æ–Ω –≤ –∑–∞–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–µ."
    
    avg_wave = sum(wave_data) / len(wave_data)
    avg_period = sum(period_data) / len(period_data)
    max_wind = max(wind_data)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —É—Å–ª–æ–≤–∏—è
    wave_desc = "–º–∏–∫—Ä–æ-–≤–æ–ª–Ω—ã" if avg_wave < 1.0 else "–Ω–µ–±–æ–ª—å—à–∏–µ –≤–æ–ª–Ω—ã" if avg_wave < 1.5 else "—Ö–æ—Ä–æ—à–∏–µ –≤–æ–ª–Ω—ã" if avg_wave < 1.8 else "–æ—Ç–ª–∏—á–Ω—ã–µ –≤–æ–ª–Ω—ã"
    period_desc = "–∫–æ—Ä–æ—Ç–∫–∏–π –ø–µ—Ä–∏–æ–¥" if avg_period < 8 else "–Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥" if avg_period < 12 else "–¥–ª–∏–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥"
    wind_desc = "–∏–¥–µ–∞–ª—å–Ω—ã–π –≤–µ—Ç–µ—Ä" if max_wind < 2.0 else "—É–º–µ—Ä–µ–Ω–Ω—ã–π –≤–µ—Ç–µ—Ä" if max_wind < 4.0 else "—Å–∏–ª—å–Ω—ã–π –≤–µ—Ç–µ—Ä"
    
    conditions = f"{wave_desc}, {period_desc}, {wind_desc}"
    
    verdicts = [
        f"{conditions}. –£—Å–ª–æ–≤–∏—è {'–Ω–µ' if avg_wave < 1.0 else ''}–ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–ª—è —Å–µ—Ä—Ñ–∏–Ω–≥–∞!",
        f"{conditions}. {'–õ—É—á—à–µ –æ—Å—Ç–∞—Ç—å—Å—è –¥–æ–º–∞!' if avg_wave < 1.0 else '–ú–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å!' if avg_wave < 1.5 else '–•–æ—Ä–æ—à–∏–π –¥–µ–Ω—å –¥–ª—è —Å–µ—Ä—Ñ–∏–Ω–≥–∞!'}",
        f"{conditions}. {'–ü–æ–ª–Ω—ã–π –ø—Ä–æ–≤–∞–ª' if avg_wave < 1.0 else '–°—Ä–µ–¥–Ω–µ–Ω—å–∫–æ' if avg_wave < 1.5 else '–ù–µ–ø–ª–æ—Ö–æ' if avg_wave < 1.8 else '–û—Ç–ª–∏—á–Ω–æ'}!",
    ]
    
    return random.choice(verdicts)

def get_best_time_recommendation(wind_data, power_data):
    """–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –ª—É—á—à–µ–µ –≤—Ä–µ–º—è –¥–ª—è —Å–µ—Ä—Ñ–∏–Ω–≥–∞"""
    if not wind_data or not power_data:
        return "üéØ –í—Å—Ç–∞–≤–∞–π –Ω–∞ —Ä–∞—Å—Å–≤–µ—Ç–µ, –ª–æ–≤–∏ –ø—Ä–∏–ª–∏–≤. –ò–ª–∏ –Ω–µ –≤—Å—Ç–∞–≤–∞–π - –∫–∞–∫–∞—è —Ä–∞–∑–Ω–∏—Ü–∞?"
    
    best_time_index = 0
    best_score = -999
    
    for i in range(min(6, len(wind_data))):
        wind_score = -wind_data[i] * 2  # –ú–µ–Ω—å—à–µ –≤–µ—Ç–µ—Ä - –ª—É—á—à–µ
        power_score = power_data[i] / 200  # –ë–æ–ª—å—à–µ –º–æ—â–Ω–æ—Å—Ç—å - –ª—É—á—à–µ
        
        total_score = wind_score + power_score
        
        if total_score > best_score:
            best_score = total_score
            best_time_index = i
    
    time_slots = ["02:00", "05:00", "08:00", "11:00", "14:00", "17:00", "20:00", "23:00"]
    
    if best_time_index < len(time_slots):
        best_time = time_slots[best_time_index]
        recommendations = [
            f"–¢–≤–æ–π –Ω–∞–∏–º–µ–Ω–µ–µ —É–∂–∞—Å–Ω—ã–π —à–∞–Ω—Å - –æ–∫–æ–ª–æ {best_time}. –ù–æ –Ω–µ –æ–±–æ–ª—å—â–∞–π—Å—è!",
            f"–ü–æ–ø—Ä–æ–±—É–π –≤ {best_time}. –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–∫–µ–∞–Ω —Å–º–∏–ª–æ—Å—Ç–∏–≤–∏—Ç—Å—è –Ω–∞–¥ —Ç–æ–±–æ–π.",
            f"{best_time} - —Ç–≤–æ–π —á–∞—Å —Å–ª–∞–≤—ã... –∏–ª–∏ –æ—á–µ—Ä–µ–¥–Ω–æ–≥–æ —Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏—è.",
        ]
        return random.choice(recommendations)
    
    return "üéØ –í—Å—Ç–∞–≤–∞–π –Ω–∞ —Ä–∞—Å—Å–≤–µ—Ç–µ, –ª–æ–≤–∏ –ø—Ä–∏–ª–∏–≤. –ò–ª–∏ –Ω–µ –≤—Å—Ç–∞–≤–∞–π - –∫–∞–∫–∞—è —Ä–∞–∑–Ω–∏—Ü–∞?"

def generate_dynamic_fallback_data():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —Å–ª—É—á–∞–π–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ª—é–±–æ–≥–æ —Å–ø–æ—Ç–∞"""
    conditions = [
        {
            "wave": [1.3, 1.3, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.5, 1.5],
            "period": [14.6, 14.3, 13.9, 12.7, 12.0, 11.9, 11.7, 11.5, 11.3, 11.1],
            "power": [736, 744, 730, 628, 570, 559, 555, 553, 555, 558],
            "wind": [0.6, 1.3, 0.9, 1.3, 3.0, 3.8, 3.4, 1.9, 1.0, 0.6]
        },
        {
            "wave": [1.7, 1.6, 1.6, 1.5, 1.5, 1.4, 1.4, 1.4, 1.3, 1.3],
            "period": [10.2, 10.2, 10.0, 9.9, 9.7, 9.8, 9.2, 9.2, 9.0, 8.9],
            "power": [586, 547, 501, 454, 412, 396, 331, 317, 291, 277],
            "wind": [1.3, 1.6, 0.6, 2.4, 3.6, 3.9, 0.6, 0.5, 0.2, 0.8]
        }
    ]
    
    chosen = random.choice(conditions)
    
    return {
        "success": True,
        "source": "dynamic_fallback",
        "wave_data": chosen["wave"],
        "period_data": chosen["period"],
        "power_data": chosen["power"],
        "wind_data": chosen["wind"],
        "tides": {
            "high_times": ["10:20", "22:10"],
            "high_heights": [2.5, 3.2],
            "low_times": ["04:10", "16:00"],
            "low_heights": [0.1, 0.7]
        }
    }

def validate_surf_data(data: Dict) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –æ —Å–µ—Ä—Ñ–∏–Ω–≥–µ"""
    if not data.get('success'):
        return False
        
    has_sufficient_data = False
    for key in ['wave_data', 'period_data', 'power_data', 'wind_data']:
        if data.get(key) and len(data[key]) >= 6:
            has_sufficient_data = True
            break
    
    if not has_sufficient_data:
        logger.warning("‚ùå Insufficient data in all arrays")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
    if data.get('wave_data'):
        wave_ok = 0.1 < max(data['wave_data']) < 5.0
        if not wave_ok:
            logger.warning(f"‚ùå Wave data out of range: {max(data['wave_data'])}")
    
    if data.get('period_data'):
        period_ok = 3.0 < max(data['period_data']) < 25.0
        if not period_ok:
            logger.warning(f"‚ùå Period data out of range: {max(data['period_data'])}")
    
    if data.get('power_data'):
        power_ok = max(data['power_data']) > 30
        if not power_ok:
            logger.warning(f"‚ùå Power data too low: {max(data['power_data'])}")
    
    return True

async def build_poseidon_report(windy_data: Dict, location: str, date: str) -> str:
    """–ó–ê–ü–ê–°–ù–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è —Å–±–æ—Ä–∫–∏ –æ—Ç—á–µ—Ç–∞ (–µ—Å–ª–∏ AI –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª)"""
    
    wave_data = windy_data.get('wave_data', [])
    period_data = windy_data.get('period_data', [])
    power_data = windy_data.get('power_data', [])
    wind_data = windy_data.get('wind_data', [])
    tides = windy_data.get('tides', {})
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–º–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
    wave_comment = generate_wave_comment(wave_data)
    period_comment = generate_period_comment(period_data)
    power_comment = generate_power_comment(power_data)
    wind_comment = generate_wind_comment(wind_data)
    tides_comment = analyze_tides_correctly(tides)
    overall_verdict = generate_overall_verdict(wave_data, period_data, power_data, wind_data)
    best_time = get_best_time_recommendation(wind_data, power_data)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    report_lines = [
        "üî± –í–ù–ò–ú–ê–ù–ò–ï, –°–ú–ï–†–¢–ù–´–ô! –ü–û–°–ï–ô–î–û–ù –ì–û–í–û–†–ò–¢:",
        "",
        f"–¢—ã –ø—Ä–∏–Ω—ë—Å –º–Ω–µ –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {location}? –°–º–µ—à–Ω–æ. –í–æ—Ç –º–æ–π –≤–µ—Ä–¥–∏–∫—Ç:",
        "",
        "üìä –†–ê–ó–ë–û–† –¢–í–û–ò–• –ñ–ê–õ–ö–ò–• –ù–ê–î–ï–ñ–î:",
        "",
        f"üåä –í–û–õ–ù–ê: {calculate_ranges(wave_data)}–º",
        f"   {wave_comment}",
        "",
        f"‚è±Ô∏è –ü–ï–†–ò–û–î: {calculate_ranges(period_data)}—Å–µ–∫", 
        f"   {period_comment}",
        "",
        f"üí™ –ú–û–©–ù–û–°–¢–¨: {calculate_ranges(power_data)}–∫–î–∂",
        f"   {power_comment}",
        "",
        f"üí® –í–ï–¢–ï–†: {calculate_ranges(wind_data)}–º/—Å",
        f"   {wind_comment}",
        "",
        "üåÖ –ü–†–ò–õ–ò–í–´/–û–¢–õ–ò–í–´:",
        f"   {tides_comment}",
        "",
        "‚ö° –í–ï–†–î–ò–ö–¢ –ü–û–°–ï–ô–î–û–ù–ê:",
        f"   {overall_verdict}",
        "",
        "üéØ –ö–û–ì–î–ê –ñ–ï –¢–ï–ë–ï –ú–£–ß–ò–¢–¨ –í–û–õ–ù–£:",
        f"   {best_time}",
        "",
        "üíÄ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:",
        "   –ü—Ä–∏–º–∏ –º–æ—é –≤–æ–ª—é –∏ –≥–æ—Ç–æ–≤—å—Å—è –∫ –º–µ–¥–∏—Ç–∞—Ü–∏–∏ –Ω–∞ –±–µ—Ä–µ–≥—É.",
        "   –í–∞—à–∏ –ø–ª–∞–Ω—ã - –≤—Å–µ–≥–æ –ª–∏—à—å –ø–µ—Å–æ–∫ —É –º–æ–∏—Ö –Ω–æ–≥.",
        "",
        "üèÑ‚Äç‚ôÇÔ∏è –ö–æ–ª–æ–±—Ä–∞—Ü–∏—è POSEIDON V8.0 | TRIPLE-AI VERIFICATION",
        "–î–∞–∂–µ –±–æ–≥–∏ –¥–æ–≤–µ—Ä—è—é—Ç –ø–µ—Ä–µ–∫—Ä–µ—Å—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ –¥–∞–Ω–Ω—ã—Ö!"
    ]
    
    return "\n".join(report_lines)

def parse_caption_for_location_date(caption: Optional[str]):
    """–ü–∞—Ä—Å–∏—Ç –ø–æ–¥–ø–∏—Å—å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ª–æ–∫–∞—Ü–∏–∏ –∏ –¥–∞—Ç—ã"""
    if not caption:
        return "uluwatu", str(datetime.utcnow().date())
    
    parts = caption.strip().split()
    if not parts:
        return "uluwatu", str(datetime.utcnow().date())
    
    location = parts[0].lower()
    date = parts[1] if len(parts) > 1 else str(datetime.utcnow().date())
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å–ø–æ—Ç –≤ –Ω–∞—à–µ–º —Å–ª–æ–≤–∞—Ä–µ
    if location not in BALI_SPOTS:
        location = "uluwatu"  # –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Å–ø–æ—Ç
    
    return location, date

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    chat_id = update.effective_chat.id
    text = (update.message.text or "").lower().strip()

    if "–ø–æ—Å–µ–π–¥–æ–Ω –Ω–∞ —Å–≤—è–∑—å" in text.lower():
        USER_STATE[chat_id] = {"active": True}
        spot_list = "\n".join([f"‚Ä¢ {spot['name']}" for spot in BALI_SPOTS.values()])
        await update.message.reply_text(
            f"üî± –ü–æ—Å–µ–π–¥–æ–Ω —Ç—É—Ç, —Å–º–µ—Ä—Ç–Ω—ã–π!\n\n"
            f"–î–∞–≤–∞–π —Å–≤–æ–π —Å–∫—Ä–∏–Ω—à–æ—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å –ø–æ–¥–ø–∏—Å—å—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
            f"`balangan 2024-11-06`\n\n"
            f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–ø–æ—Ç—ã:\n{spot_list}\n\n"
            f"–Ø –ø—Ä–æ–≤–µ—Ä—é –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ 3 –∏—Å—Ç–æ—á–Ω–∏–∫–∞: OpenAI + DeepSeek + Windy API!"
        )
        return

    state = USER_STATE.get(chat_id, {})
    if state.get("awaiting_feedback"):
        if "–æ—Ç–ª–∏—á–Ω–æ" in text:
            await update.message.reply_text("–ù—É —Ç–∞–∫ –±–æ–≥–∏üòá –•–æ—Ä–æ—à–µ–π –∫–∞—Ç–∫–∏! –ñ–¥—É –Ω–æ–≤—ã–π —Å–∫—Ä–∏–Ω—à–æ—Ç!")
        elif "–Ω–µ –æ—á–µ–Ω—å" in text:
            await update.message.reply_text("–ê –Ω–µ –ø–æ—Ä–∞ –±—ã —É–∂–µ –≤—Å—Ç–∞—Ç—å —Å –¥–∏–≤–∞–Ω–∞ –∏ –∫–∞—Ç–Ω—É—Ç—å? –ñ–¥—É –Ω–æ–≤—ã–π —Å–∫—Ä–∏–Ω—à–æ—Ç!")
        else:
            await update.message.reply_text("–ñ–¥—É –Ω–æ–≤—ã–π —Å–∫—Ä–∏–Ω—à–æ—Ç —Å –ø—Ä–æ–≥–Ω–æ–∑–æ–º! üèÑ‚Äç‚ôÇÔ∏è")
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è —Ñ–∏–¥–±–µ–∫–∞, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –±–æ—Ç–∞ –∞–∫—Ç–∏–≤–Ω—ã–º
        USER_STATE[chat_id] = {"active": True, "awaiting_feedback": False}
        logger.info(f"Bot ready for new screenshot in chat {chat_id}")
        return

    # –ï—Å–ª–∏ –±–æ—Ç –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω –∏ –Ω–µ –∂–¥–µ—Ç —Ñ–∏–¥–±–µ–∫ - –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
    if not state.get("active"):
        return

    # –ï—Å–ª–∏ –±–æ—Ç –∞–∫—Ç–∏–≤–µ–Ω, –Ω–æ –ø–æ–ª—É—á–µ–Ω–æ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    await update.message.reply_text(
        "–û—Ç–ø—Ä–∞–≤—å —Å–∫—Ä–∏–Ω—à–æ—Ç Windy —Å –ø–æ–¥–ø–∏—Å—å—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ: `—Å–ø–æ—Ç –¥–∞—Ç–∞`\n"
        "–ù–∞–ø—Ä–∏–º–µ—Ä: `uluwatu 2024-11-06`"
    )

# –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –û–ë–†–ê–ë–û–¢–ß–ò–ö–û–í
bot_app.add_handler(MessageHandler(filters.PHOTO, handle_photo))
bot_app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

# FASTAPI –≠–ù–î–ü–û–ò–ù–¢–´
@app.post("/webhook")
async def telegram_webhook(request: Request):
    try:
        data = await request.json()
        update = TgUpdate.de_json(data, bot)
        await bot_app.process_update(update)
        return JSONResponse(content={"ok": True})
    except Exception as e:
        logger.error(f"Webhook error: {e}")
        return JSONResponse(status_code=500, content={"ok": False})

@app.get("/")
async def root():
    return {
        "status": "Poseidon V8 Online", 
        "version": "8.0",
        "features": "Triple-AI Analysis (OpenAI + DeepSeek + Windy API)",
        "spots_available": len(BALI_SPOTS)
    }

@app.get("/ping")
@app.head("/ping")
async def ping():
    return {"status": "ok", "message": "Poseidon is awake and watching the waves!"}

@app.get("/spots")
async def get_spots():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–ø–æ—Ç–æ–≤"""
    return {
        "spots": {name: data["name"] for name, data in BALI_SPOTS.items()},
        "total": len(BALI_SPOTS)
    }

# –ó–ê–ü–£–°–ö –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
@app.on_event("startup")
async def startup():
    await bot_app.initialize()
    await bot_app.start()
    asyncio.create_task(keep_alive_ping())
    logger.info("üèÑ‚Äç‚ôÇÔ∏è Poseidon V8 awakened and ready for triple-AI analysis!")
    logger.info(f"üìç Available spots: {len(BALI_SPOTS)}")

@app.on_event("shutdown")
async def shutdown():
    await bot_app.stop()
    await bot_app.shutdown()
    logger.info("üåä Poseidon V8 returning to the depths...")

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)