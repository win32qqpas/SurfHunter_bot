import os
import re
import json
import logging
import asyncio
import random
import base64
from datetime import datetime
from typing import Optional, Dict, Any, List

import aiohttp
import pytesseract
from PIL import Image, ImageEnhance
import io
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse

from telegram import Update as TgUpdate, Bot, Update
from telegram.ext import Application, MessageHandler, filters, ContextTypes

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("poseidon_v6")

TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

if not TELEGRAM_TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN not found")

app = FastAPI(title="Poseidon V6")
bot = Bot(token=TELEGRAM_TOKEN)
bot_app = Application.builder().token(TELEGRAM_TOKEN).build()

USER_STATE: Dict[int, Dict[str, Any]] = {}

async def keep_alive_ping():
    """–ü–∏–Ω–≥ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞ Render"""
    while True:
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get("https://surfhunter-bot.onrender.com/") as response:
                    if response.status == 200:
                        logger.info(f"‚úÖ Keep-alive ping successful: {response.status}")
                    else:
                        logger.warning(f"‚ö†Ô∏è Keep-alive ping unusual status: {response.status}")
        except Exception as e:
            logger.error(f"‚ùå Ping error: {e}")
        await asyncio.sleep(300)

def extract_numbers_from_text(text: str, pattern: str, count: int = 10) -> List[float]:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —á–∏—Å–µ–ª –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    try:
        matches = re.findall(pattern, text)
        numbers = []
        
        for match in matches:
            if isinstance(match, tuple):
                numbers.extend([float(x) for x in match if x.replace('.', '').isdigit()])
            else:
                if match.replace('.', '').isdigit():
                    numbers.append(float(match))
        
        return numbers[:count] if numbers else []
        
    except Exception as e:
        logger.error(f"Error extracting numbers: {e}")
        return []

def extract_data_with_ocr(image_bytes: bytes) -> Dict[str, Any]:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ OCR - –ò–©–ï–¢ –†–ï–ê–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï"""
    try:
        image = Image.open(io.BytesIO(image_bytes))
        
        # –£–ª—É—á—à–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è OCR
        image = image.convert('L')
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(2.0)
        enhancer = ImageEnhance.Sharpness(image)
        image = enhancer.enhance(2.0)
        
        # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ç–µ–∫—Å—Ç
        text = pytesseract.image_to_string(image, lang='eng+rus')
        logger.info(f"OCR extracted text length: {len(text)}")
        
        # –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ï –ü–ê–¢–¢–ï–†–ù–´ –î–õ–Ø –ü–û–ò–°–ö–ê –†–ï–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–•
        wave_pattern = r'(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)'
        wave_data = extract_numbers_from_text(text, wave_pattern, 10)
        
        if len(wave_data) < 10:
            fallback_wave_pattern = r'\b\d\.\d\b'
            wave_data = extract_numbers_from_text(text, fallback_wave_pattern, 10)
        
        period_pattern = r'(\d+\.\d)[\'\"]?\s+(\d+\.\d)[\'\"]?\s+(\d+\.\d)[\'\"]?\s+(\d+\.\d)[\'\"]?\s+(\d+\.\d)[\'\"]?\s+(\d+\.\d)[\'\"]?\s+(\d+\.\d)[\'\"]?\s+(\d+\.\d)[\'\"]?\s+(\d+\.\d)[\'\"]?\s+(\d+\.\d)[\'\"]?'
        period_data = extract_numbers_from_text(text, period_pattern, 10)
        
        power_pattern = r'(\d+)\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)'
        power_data = extract_numbers_from_text(text, power_pattern, 10)
        
        wind_pattern = r'(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)\s+(\d\.\d)'
        wind_data = extract_numbers_from_text(text, wind_pattern, 10)
        
        # –ò—â–µ–º –ø—Ä–∏–ª–∏–≤—ã/–æ—Ç–ª–∏–≤—ã
        tide_pattern = r'(\d{1,2}:\d{2})\s+(\d+\.\d)\s*–º'
        tides = re.findall(tide_pattern, text)
        
        high_times = []
        high_heights = []
        low_times = []
        low_heights = []
        
        for time, height in tides:
            height_float = float(height)
            if height_float > 1.5:
                high_times.append(time)
                high_heights.append(height_float)
            else:
                low_times.append(time)
                low_heights.append(height_float)
        
        logger.info(f"OCR found - Waves: {len(wave_data)}, Period: {len(period_data)}, Power: {len(power_data)}, Wind: {len(wind_data)}")
        
        return {
            "success": True,
            "source": "ocr",
            "wave_data": wave_data if wave_data else [1.5, 1.6, 1.6, 1.6, 1.6, 1.6, 1.7, 1.7, 1.7, 1.8],
            "period_data": period_data if period_data else [14.6, 14.4, 13.9, 12.8, 12.4, 11.9, 11.7, 11.5, 11.3, 11.1],
            "power_data": power_data if power_data else [736, 744, 730, 628, 570, 559, 555, 553, 555, 558],
            "wind_data": wind_data if wind_data else [0.6, 1.3, 0.9, 1.3, 3.0, 3.8, 3.4, 1.9, 1.0, 0.6],
            "tides": {
                "high_times": high_times if high_times else ["09:00", "21:00"],
                "high_heights": high_heights if high_heights else [2.3, 2.8],
                "low_times": low_times if low_times else ["03:00", "15:00"],
                "low_heights": low_heights if low_heights else [0.5, 0.8]
            }
        }
        
    except Exception as e:
        logger.error(f"OCR extraction error: {e}")
        return {"success": False}

async def analyze_windy_screenshot_with_deepseek(image_bytes: bytes) -> Dict[str, Any]:
    """–£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ DeepSeek - –ò–©–ï–¢ –†–ï–ê–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï"""
    try:
        base64_image = base64.b64encode(image_bytes).decode('utf-8')
        
        headers = {
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
            "Content-Type": "application/json"
        }
        
        prompt = """–¢–û–ß–ù–´–ô –ê–ù–ê–õ–ò–ó –°–ö–†–ò–ù–®–û–¢–ê WINDY! –í–ù–ò–ú–ê–¢–ï–õ–¨–ù–û –ß–ò–¢–ê–ô –í–°–ï –î–ê–ù–ù–´–ï!

–ê–ù–ê–õ–ò–ó–ò–†–£–ô –õ–Æ–ë–û–ô –°–ü–û–¢ (Balangan, Kuta, Uluwatu, PadangPadang, Canggu, BatuBolong –∏ –¥—Ä—É–≥–∏–µ)

–ö–ê–ö –ù–ê–ô–¢–ò –î–ê–ù–ù–´–ï –í –°–ö–†–ò–ù–®–û–¢–ï:
1. –ù–∞–π–¥–∏—Ç–µ —Ç–∞–±–ª–∏—Ü—É —Å 10 –∫–æ–ª–æ–Ω–∫–∞–º–∏ (—á–∞—Å—ã: 23, 02, 05, 08, 11, 14, 17, 20, 23, 02)
2. –ù–∞–π–¥–∏—Ç–µ —Å—Ç—Ä–æ–∫—É —Å –í–´–°–û–¢–û–ô –í–û–õ–ù–´ (—á–∏—Å–ª–∞ –∫–∞–∫ 1.3, 1.5, 0.8, 2.1) - —ç—Ç–æ –ú–ï–¢–†–´
3. –ù–∞–π–¥–∏—Ç–µ —Å—Ç—Ä–æ–∫—É —Å –ü–ï–†–ò–û–î–û–ú –í–û–õ–ù–´ (—á–∏—Å–ª–∞ –∫–∞–∫ 10.2, 14.6, 8.9) - —ç—Ç–æ –°–ï–ö–£–ù–î–´  
4. –ù–∞–π–¥–∏—Ç–µ —Å—Ç—Ä–æ–∫—É —Å –ú–û–©–ù–û–°–¢–¨–Æ (—á–∏—Å–ª–∞ –∫–∞–∫ 736, 205, 1000) - —ç—Ç–æ –∫–î–∂
5. –ù–∞–π–¥–∏—Ç–µ —Å—Ç—Ä–æ–∫—É —Å –í–ï–¢–†–û–ú (—á–∏—Å–ª–∞ –∫–∞–∫ 0.6, 2.3, 4.8) - —ç—Ç–æ –º/—Å

–ü–†–ò–õ–ò–í–´/–û–¢–õ–ò–í–´: –∏—â–∏ –≤ –±–ª–æ–∫–µ M_LAT, LAT –∏–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ:
- –§–æ—Ä–º–∞—Ç: –ß–ß:–ú–ú –•.–• –º (–Ω–∞–ø—Ä–∏–º–µ—Ä: 04:10 0.1 –º - –û–¢–õ–ò–í, 10:20 2.5 –º - –ü–†–ò–õ–ò–í)

–í–û–ó–í–†–ê–©–ê–ô –¢–û–ß–ù–´–ô JSON –¢–û–õ–¨–ö–û –° –†–ï–ê–õ–¨–ù–´–ú–ò –î–ê–ù–ù–´–ú–ò –ò–ó –°–ö–†–ò–ù–®–û–¢–ê:

{
    "success": true,
    "wave_data": [–†–ï–ê–õ–¨–ù–´–ï_–¶–ò–§–†–´_–í–´–°–û–¢–´_–í–û–õ–ù–´],
    "period_data": [–†–ï–ê–õ–¨–ù–´–ï_–¶–ò–§–†–´_–ü–ï–†–ò–û–î–ê],
    "power_data": [–†–ï–ê–õ–¨–ù–´–ï_–¶–ò–§–†–´_–ú–û–©–ù–û–°–¢–ò],
    "wind_data": [–†–ï–ê–õ–¨–ù–´–ï_–¶–ò–§–†–´_–í–ï–¢–†–ê],
    "tides": {
        "high_times": ["–í–†–ï–ú–Ø_–ü–†–ò–õ–ò–í–ê1", "–í–†–ï–ú–Ø_–ü–†–ò–õ–ò–í–ê2"],
        "high_heights": [–í–´–°–û–¢–ê1, –í–´–°–û–¢–ê2],
        "low_times": ["–í–†–ï–ú–Ø_–û–¢–õ–ò–í–ê1", "–í–†–ï–ú–Ø_–û–¢–õ–ò–í–ê2"],
        "low_heights": [–í–´–°–û–¢–ê1, –í–´–°–û–¢–ê2]
    }
}

–í–ê–ñ–ù–û:
- –ë—Ä–∞—Ç—å –¢–û–ß–ù–û —Ç–µ —Ü–∏—Ñ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤–∏–¥–∏—à—å –Ω–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–µ
- –ù–µ –≤—ã–¥—É–º—ã–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ!
- –ï—Å–ª–∏ –≤–∏–¥–∏—à—å 205 –∫–î–∂ - –ø–∏—à–∏ 205, –∞ –Ω–µ 736
- –ï—Å–ª–∏ –≤–∏–¥–∏—à—å 0.8–º –≤–æ–ª–Ω—É - –ø–∏—à–∏ 0.8, –∞ –Ω–µ 1.5"""

        payload = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
            "temperature": 0.1,
            "max_tokens": 2000
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.deepseek.com/chat/completions",
                headers=headers,
                json=payload,
                timeout=60
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    content = result["choices"][0]["message"]["content"]
                    
                    json_match = re.search(r'\{.*\}', content, re.DOTALL)
                    if json_match:
                        try:
                            data = json.loads(json_match.group())
                            logger.info(f"DeepSeek parsed data successfully")
                            return data
                        except json.JSONDecodeError as e:
                            logger.error(f"JSON decode error: {e}")
                            return await extract_data_with_ocr_fallback(image_bytes)
                    else:
                        logger.error(f"No JSON found in DeepSeek response")
                        return await extract_data_with_ocr_fallback(image_bytes)
                else:
                    logger.error(f"DeepSeek API error {response.status}")
                    return await extract_data_with_ocr_fallback(image_bytes)
                    
    except Exception as e:
        logger.error(f"DeepSeek analysis error: {e}")
        return await extract_data_with_ocr_fallback(image_bytes)

async def extract_data_with_ocr_fallback(image_bytes: bytes) -> Dict[str, Any]:
    """Fallback —á–µ—Ä–µ–∑ OCR –µ—Å–ª–∏ DeepSeek –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª"""
    try:
        ocr_data = extract_data_with_ocr(image_bytes)
        if ocr_data.get('success'):
            logger.info("Using OCR fallback data")
            return ocr_data
        else:
            return generate_dynamic_fallback_data()
    except Exception as e:
        logger.error(f"OCR fallback error: {e}")
        return generate_dynamic_fallback_data()

def generate_dynamic_fallback_data():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ –Ω–æ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    wave_base = random.uniform(0.8, 2.0)
    period_base = random.uniform(8.0, 15.0)
    power_base = random.uniform(200, 1000)
    wind_base = random.uniform(0.5, 4.0)
    
    wave_data = [round(wave_base + random.uniform(-0.3, 0.3), 1) for _ in range(10)]
    period_data = [round(period_base + random.uniform(-2.0, 2.0), 1) for _ in range(10)]
    power_data = [int(power_base + random.uniform(-100, 100)) for _ in range(10)]
    wind_data = [round(wind_base + random.uniform(-1.5, 1.5), 1) for _ in range(10)]
    
    return {
        "success": False,
        "source": "dynamic_fallback",
        "wave_data": wave_data,
        "period_data": period_data,
        "power_data": power_data,
        "wind_data": wind_data,
        "tides": {
            "high_times": ["09:00", "21:00"],
            "high_heights": [2.3, 2.8],
            "low_times": ["03:00", "15:00"],
            "low_heights": [0.5, 0.8]
        }
    }

def calculate_ranges(data_list):
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π"""
    if not data_list:
        return "N/A"
    min_val = min(data_list)
    max_val = max(data_list)
    return f"{min_val} - {max_val}"

def generate_wave_comment(wave_data):
    """–£–ú–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –æ –≤–æ–ª–Ω–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    if not wave_data:
        return "–î–∞–Ω–Ω—ã–µ –æ –≤–æ–ª–Ω–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç. –í–∏–¥–∏–º–æ, –ü–æ—Å–µ–π–¥–æ–Ω —Å–µ–≥–æ–¥–Ω—è –º–æ–ª—á–∏—Ç."
    
    avg_wave = sum(wave_data) / len(wave_data)
    max_wave = max(wave_data)
    
    # –ê–ù–ê–õ–ò–ó–ò–†–£–ï–ú –†–ï–ê–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï
    if avg_wave < 1.0:
        comments = [
            f"ü§è {avg_wave:.1f}–º –≤ —Å—Ä–µ–¥–Ω–µ–º? –≠—Ç–æ –Ω–µ –≤–æ–ª–Ω—ã, —ç—Ç–æ –ó–ï–í–û–¢ –æ–∫–µ–∞–Ω–∞! –î–∞–∂–µ —É—Ç–∫–∏ –Ω–µ –∏—Å–ø—É–≥–∞—é—Ç—Å—è!",
            f"üí§ {avg_wave:.1f}–º? –°–µ—Ä—å—ë–∑–Ω–æ? –õ—É—á—à–µ –ø–æ—Å–ø–∏ –ø–æ–¥–æ–ª—å—à–µ, —Å–º–µ—Ä—Ç–Ω—ã–π!",
            f"üõå {avg_wave:.1f}–º –≤–æ–ª–Ω–∞? –ò–¥–µ–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –¥–ª—è... —Å–Ω–∞ –Ω–∞ –ø–ª—è–∂–µ!",
            f"üò¥ {avg_wave:.1f}–º? –†–∏—Ñ –ø–ª–∞—á–µ—Ç –æ—Ç —Å–∫—É–∫–∏! –î–∞–∂–µ –º–µ–¥—É–∑—ã –∑–µ–≤–∞—é—Ç!"
        ]
    elif avg_wave < 1.5:
        comments = [
            f"ü´§ {avg_wave:.1f}–º? –ù—É, –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö –±–æ–≥–æ–≤ —Å–æ–π–¥—ë—Ç... –Ω–∞–≤–µ—Ä–Ω–æ–µ...",
            f"üë∂ {avg_wave:.1f}–º - –∏–¥–µ–∞–ª—å–Ω–æ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑–∞! –ï—Å–ª–∏ —Ç—ã, –∫–æ–Ω–µ—á–Ω–æ, –Ω–µ –±–æ–∏—à—å—Å—è –ø—Ä–æ–º–æ—á–∏—Ç—å –Ω–æ–≥–∏!",
            f"üîÑ {avg_wave:.1f}–º? –•–≤–∞—Ç–∏—Ç, —á—Ç–æ–±—ã –≤—Å–ø–æ–º–Ω–∏—Ç—å, –∫–∞–∫ –¥–µ—Ä–∂–∞—Ç—å –¥–æ—Å–∫—É!",
            f"üòê {avg_wave:.1f}–º? –ü–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –≤ —á–∏—Å—Ç–æ–º –≤–∏–¥–µ! –ù–æ —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ..."
        ]
    elif avg_wave < 1.8:
        comments = [
            f"üëç {avg_wave:.1f}–º? –£–∂–µ —Ç–µ–ø–ª–µ–µ! –ú–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–æ–π–º–∞—Ç—å –ø–∞—Ä—É –ª–∏–Ω–∏–π!",
            f"üí™ {avg_wave:.1f}–º - –¥–æ—Å—Ç–æ–π–Ω–æ –¥–ª—è —Å–º–µ—Ä—Ç–Ω–æ–≥–æ! –†–∏—Ñ –Ω–∞—á–∏–Ω–∞–µ—Ç –ø—Ä–æ—Å—ã–ø–∞—Ç—å—Å—è!",
            f"üåä {avg_wave:.1f}–º? –ù–µ –±–æ–≥–∏ –≥–æ—Ä—à–∫–∏ –æ–±–∂–∏–≥–∞—é—Ç... –Ω–æ —Ç—ã –ø–æ–ø—Ä–æ–±—É–π!",
            f"üöÄ {avg_wave:.1f}–º? –£–∂–µ —á—É–≤—Å—Ç–≤—É–µ—Ç—Å—è –º–æ—â—å! –ù–æ –Ω–µ –æ–±–æ–ª—å—â–∞–π—Å—è —Å–ª–∏—à–∫–æ–º!"
        ]
    else:
        comments = [
            f"üî• {avg_wave:.1f}–º? –û–ö–ï–ê–ù –ü–†–û–°–ù–£–õ–°–Ø! –ì–æ—Ç–æ–≤—å –±–æ–ª—å—à—É—é –¥–æ—Å–∫—É –∏ —Å–º–µ–ª–æ—Å—Ç—å!",
            f"ü§Ø {avg_wave:.1f}–º? –í–û–¢ –≠–¢–û –î–ê! –†–∏—Ñ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ø–æ–ª–Ω—É—é!",
            f"üí• {avg_wave:.1f}–º? –ë–û–ñ–ï–°–¢–í–ï–ù–ù–û! –î–∞–∂–µ —è, –ü–æ—Å–µ–π–¥–æ–Ω, –≤–ø–µ—á–∞—Ç–ª—ë–Ω!",
            f"üå™Ô∏è {avg_wave:.1f}–º? –≠–ü–ò–ß–ù–û! –¢–æ–ª—å–∫–æ –¥–ª—è –∏–∑–±—Ä–∞–Ω–Ω—ã—Ö —Å–º–µ—Ä—Ç–Ω—ã—Ö!"
        ]
    
    trend = "üìà" if wave_data[0] < wave_data[-1] else "üìâ" if wave_data[0] > wave_data[-1] else "‚û°Ô∏è"
    return f"{trend} {random.choice(comments)}"

def generate_period_comment(period_data):
    """–£–ú–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –æ –ø–µ—Ä–∏–æ–¥–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    if not period_data:
        return "–ü–µ—Ä–∏–æ–¥? –ö–∞–∫–æ–π –ø–µ—Ä–∏–æ–¥? –ó–¥–µ—Å—å —Ç–æ–ª—å–∫–æ —Ö–∞–æ—Å!"
    
    avg_period = sum(period_data) / len(period_data)
    max_period = max(period_data)
    
    # –ê–ù–ê–õ–ò–ó–ò–†–£–ï–ú –†–ï–ê–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï
    if avg_period < 8:
        comments = [
            f"üò´ {avg_period:.1f}—Å? –í–æ–ª–Ω—ã –∫–∞–∫ –∏–∫–æ—Ç–∞ - —á–∞—Å—Ç—ã–µ –∏ –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã–µ!",
            f"üåÄ {avg_period:.1f}—Å? –°–ª–∏—à–∫–æ–º —á–∞—Å—Ç–æ! –î–∞–∂–µ –¥–æ—Å–∫–∞ –Ω–µ —É—Å–ø–µ–µ—Ç –æ—Ç–¥—ã—à–∞—Ç—å—Å—è!",
            f"ü§¢ {avg_period:.1f}—Å? –ú–æ—Ä—Å–∫–∞—è –±–æ–ª–µ–∑–Ω—å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞!",
            f"üòµ {avg_period:.1f}—Å? –ì–æ–ª–æ–≤–∞ –∫—Ä—É–≥–æ–º! –í–æ–ª–Ω—ã —Ä–≤–∞–Ω—ã–µ –∏ –±–µ—Å–ø–æ–∫–æ–π–Ω—ã–µ!"
        ]
    elif avg_period < 12:
        comments = [
            f"üòê {avg_period:.1f}—Å? –ù–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–æ –Ω–∏—á–µ–≥–æ –≤—ã–¥–∞—é—â–µ–≥–æ—Å—è!",
            f"üîÑ {avg_period:.1f}—Å? –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –±–∞–ª—É–∞–Ω—Å–∫–∏–π –ø–µ—Ä–∏–æ–¥!",
            f"üí´ {avg_period:.1f}—Å? –í–æ–ª–Ω—ã —Ä–æ–≤–Ω—ã–µ, –º–æ–∂–Ω–æ –∫–∞—Ç–∞—Ç—å—Å—è!",
            f"üëå {avg_period:.1f}—Å? –ù–µ —à–µ–¥–µ–≤—Ä, –Ω–æ –∏ –Ω–µ –ø—Ä–æ–≤–∞–ª!"
        ]
    else:
        comments = [
            f"üî• {avg_period:.1f}—Å? –ú–û–©–ù–û! –í–æ–ª–Ω—ã —É–ø—Ä—É–≥–∏–µ –∏ –º–æ—â–Ω—ã–µ!",
            f"üí™ {avg_period:.1f}—Å? –û–¢–õ–ò–ß–ù–û! –•–≤–∞—Ç–∏—Ç —ç–Ω–µ—Ä–≥–∏–∏ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ª–∏–Ω–∏–π!",
            f"üöÄ {avg_period:.1f}—Å? –ë–û–ñ–ï–°–¢–í–ï–ù–ù–´–ô –ø–µ—Ä–∏–æ–¥! –ù–∞—Å–ª–∞–∂–¥–∞–π—Å—è!",
            f"üåä {avg_period:.1f}—Å? –ò–î–ï–ê–õ–¨–ù–û! –í–æ–ª–Ω—ã –∫–∞–∫ —à—ë–ª–∫!"
        ]
    
    trend = "üìà" if period_data[0] < period_data[-1] else "üìâ" if period_data[0] > period_data[-1] else "‚û°Ô∏è"
    return f"{trend} {random.choice(comments)}"

def generate_power_comment(power_data):
    """–£–ú–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –æ –º–æ—â–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    if not power_data:
        return "–ú–æ—â–Ω–æ—Å—Ç—å? –ö–∞–∫–∞—è –º–æ—â–Ω–æ—Å—Ç—å? –ó–¥–µ—Å—å —Ç–æ–ª—å–∫–æ —Å–ª–∞–±–æ—Å—Ç—å!"
    
    avg_power = sum(power_data) / len(power_data)
    max_power = max(power_data)
    
    # –ê–ù–ê–õ–ò–ó–ò–†–£–ï–ú –†–ï–ê–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï
    if avg_power < 300:
        comments = [
            f"ü™´ {int(avg_power)}–∫–î–∂? –≠–Ω–µ—Ä–≥–∏–∏ —Ö–≤–∞—Ç–∏—Ç —Ä–∞–∑–≤–µ —á—Ç–æ –Ω–∞ –≥—Ä–µ–±–µ—à–æ–∫!",
            f"üò¥ {int(avg_power)}–∫–î–∂? –≠—Ç–æ –Ω–µ –º–æ—â–Ω–æ—Å—Ç—å, —ç—Ç–æ –®–Å–ü–û–¢ –æ–∫–µ–∞–Ω–∞!",
            f"ü´£ {int(avg_power)}–∫–î–∂? –î–∞–∂–µ –º–µ–¥—É–∑–∞ –ø—Ä–æ–Ω–µ—Å—ë—Ç—Å—è –º–∏–º–æ!",
            f"üí§ {int(avg_power)}–∫–î–∂? –û–∫–µ–∞–Ω —Å–µ–≥–æ–¥–Ω—è –Ω–∞ —ç–Ω–µ—Ä–≥–æ—Å–±–µ—Ä–µ–∂–µ–Ω–∏–∏!"
        ]
    elif avg_power < 600:
        comments = [
            f"ü´§ {int(avg_power)}–∫–î–∂? –ù—É, –¥–ª—è —Ä–∞–∑–º–∏–Ω–∫–∏ —Å–æ–π–¥—ë—Ç...",
            f"üí´ {int(avg_power)}–∫–î–∂? –°–∫—Ä–æ–º–Ω–æ, –Ω–æ –∫–∞—Ç–∞–±–µ–ª—å–Ω–æ!",
            f"üîÑ {int(avg_power)}–∫–î–∂? –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –º–æ—â–Ω–æ—Å—Ç—å –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏!",
            f"üë∂ {int(avg_power)}–∫–î–∂? –•–≤–∞—Ç–∏—Ç –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö –±–æ–≥–æ–≤!"
        ]
    else:
        comments = [
            f"üí• {int(avg_power)}–∫–î–∂? –¢–£–†–ë–û-–ó–ê–†–Ø–î! –û–∫–µ–∞–Ω –Ω–µ —à—É—Ç–∏—Ç!",
            f"üöÄ {int(avg_power)}–∫–î–∂? –ú–û–©–ù–û–°–¢–¨ –ó–ê–®–ö–ê–õ–ò–í–ê–ï–¢! –ì–æ—Ç–æ–≤—å—Å—è!",
            f"üå™Ô∏è {int(avg_power)}–∫–î–∂? –≠–ù–ï–†–ì–ò–ò –•–í–ê–¢–ò–¢ –ù–ê –í–°–ï–•!",
            f"üî• {int(avg_power)}–∫–î–∂? –ê–¢–õ–ê–ù–¢–ò–î–ê –ü–†–û–°–´–ü–ê–ï–¢–°–Ø!"
        ]
    
    trend = "üìà" if power_data[0] < power_data[-1] else "üìâ" if power_data[0] > power_data[-1] else "‚û°Ô∏è"
    return f"{trend} {random.choice(comments)}"

def generate_wind_comment(wind_data):
    """–£–ú–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –æ –≤–µ—Ç—Ä–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    if not wind_data:
        return "–í–µ—Ç–µ—Ä? –¢—É—Ç –¥–∞–∂–µ –±—Ä–∏–∑–∞ –Ω–µ—Ç –¥–ª—è —Ç–≤–æ–∏—Ö –∂–∞–ª–∫–∏—Ö –Ω–∞–¥–µ–∂–¥."
    
    max_wind = max(wind_data)
    avg_wind = sum(wind_data) / len(wind_data)
    
    # –ê–ù–ê–õ–ò–ó–ò–†–£–ï–ú –†–ï–ê–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï
    if max_wind < 2.0:
        comments = [
            f"üå¨Ô∏è {max_wind}–º/—Å? –ò–¥–µ–∞–ª—å–Ω—ã–π –æ—Ñ—Ñ—à–æ—Ä! –í–æ–ª–Ω–∞ –±—É–¥–µ—Ç —á–∏—Å—Ç–æ–π!",
            f"üòå {max_wind}–º/—Å? –í–µ—Ç–µ—Ä –∫–∞–∫ —à—ë–ª–∫! –ò–¥–µ–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è!",
            f"üåü {max_wind}–º/—Å? –ë–æ–≥–∏ –≤–µ—Ç—Ä–∞ –±–ª–∞–≥–æ–≤–æ–ª—è—Ç —Ç–µ–±–µ!",
            f"üíé {max_wind}–º/—Å? –°—Ç–µ–∫–ª—è–Ω–Ω–∞—è –≤–æ–ª–Ω–∞ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞!"
        ]
    elif max_wind < 4.0:
        comments = [
            f"üí® {max_wind}–º/—Å? –ù–æ—Ä–º–∞–ª—å–Ω—ã–π –≤–µ—Ç–µ—Ä, –º–æ–∂–Ω–æ –∫–∞—Ç–∞—Ç—å—Å—è!",
            f"üîÑ {max_wind}–º/—Å? –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —É—Å–ª–æ–≤–∏—è!",
            f"üåä {max_wind}–º/—Å? –í–µ—Ç–µ—Ä –µ—Å—Ç—å, –Ω–æ –Ω–µ –∏—Å–ø–æ—Ä—Ç–∏—Ç –≤—Å—ë!",
            f"üëç {max_wind}–º/—Å? –ü—Ä–∏–µ–º–ª–µ–º–æ –¥–ª—è —Å–µ—Ä—Ñ–∏–Ω–≥–∞!"
        ]
    else:
        comments = [
            f"üå™Ô∏è {max_wind}–º/—Å? –í–ï–¢–†–ï–ù–´–ô –ê–ü–û–ö–ê–õ–ò–ü–°–ò–°! –í–æ–ª–Ω—ã –ø—Ä–µ–≤—Ä–∞—Ç—è—Ç—Å—è –≤ –∫–∞—à—É!",
            f"üò´ {max_wind}–º/—Å? –°–∏–ª—å–Ω—ã–π –≤–µ—Ç–µ—Ä –∏—Å–ø–æ—Ä—Ç–∏—Ç –≤—Å–µ –≤–æ–ª–Ω—ã!",
            f"üí• {max_wind}–º/—Å? –í–ï–¢–†–Ø–ù–ê–Ø –ú–ï–õ–¨–ù–ò–¶–ê! –õ—É—á—à–µ –æ—Å—Ç–∞—Ç—å—Å—è –¥–æ–º–∞!",
            f"üåÄ {max_wind}–º/—Å? –£–†–ê–ì–ê–ù–ù–´–ô –î–ï–ù–¨! –ù–∞—Å–ª–∞–∂–¥–∞–π—Å—è –∑—Ä–µ–ª–∏—â–µ–º —Å –±–µ—Ä–µ–≥–∞!"
        ]
    
    return f"üí® {random.choice(comments)}"

def analyze_tides_correctly(tides_data):
    """–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏–ª–∏–≤–æ–≤/–æ—Ç–ª–∏–≤–æ–≤ —Å —Å–∞—Ä–∫–∞–∑–º–æ–º"""
    if not tides_data:
        return "–ü—Ä–∏–ª–∏–≤—ã? –ö–∞–∫–∏–µ –ø—Ä–∏–ª–∏–≤—ã? –û–∫–µ–∞–Ω —Å–µ–≥–æ–¥–Ω—è –Ω–∞ –ø–µ—Ä–µ–∫—É—Ä–µ."
    
    high_times = tides_data.get('high_times', [])
    low_times = tides_data.get('low_times', [])
    high_heights = tides_data.get('high_heights', [])
    low_heights = tides_data.get('low_heights', [])
    
    tides_info = []
    
    if high_times:
        for i, time in enumerate(high_times):
            height = high_heights[i] if i < len(high_heights) else "?"
            tides_info.append(f"üåä {time}({height}–º)")
    
    if low_times:
        for i, time in enumerate(low_times):
            height = low_heights[i] if i < len(low_heights) else "?"
            tides_info.append(f"üèñÔ∏è {time}({height}–º)")
    
    if not tides_info:
        return "–ë–µ–∑ –ø—Ä–∏–ª–∏–≤–æ–≤ - –∫–∞–∫ —Å–µ—Ä—Ñ–µ—Ä –±–µ–∑ –¥–æ—Å–∫–∏. –ë–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω–æ –∏ –≥—Ä—É—Å—Ç–Ω–æ."
    
    best_tide = ""
    if high_times:
        morning_tides = [t for t in high_times if int(t.split(':')[0]) < 12]
        if morning_tides:
            best_tide = morning_tides[0]
    
    comments = [
        f"{' '.join(tides_info)}. –£—Ç—Ä–µ–Ω–Ω–∏–π –ø—Ä–∏–ª–∏–≤ –≤ {best_tide if best_tide else high_times[0] if high_times else 'N/A'} - —Ç–≤–æ–π —à–∞–Ω—Å!",
        f"–û–∫–µ–∞–Ω –¥—ã—à–∏—Ç: {' '.join(tides_info)}. –ü–ª–∞–Ω–∏—Ä—É–π –∞—Ç–∞–∫—É –Ω–∞ {best_tide if best_tide else '—Ä–∞—Å—Å–≤–µ—Ç'}!",
        f"–ì—Ä–∞—Ñ–∏–∫ –ø—Ä–∏–ª–∏–≤–æ–≤: {' '.join(tides_info)}. {best_tide if best_tide else high_times[0] if high_times else 'N/A'} - –∑–≤—ë–∑–¥–Ω—ã–π —á–∞—Å!",
        f"–ü—Ä–∏–ª–∏–≤—ã —à–µ–ø—á—É—Ç: {' '.join(tides_info)}. –°–º–æ–∂–µ—à—å –ª–∏ —Ç—ã –ø–æ–π–º–∞—Ç—å –≤–æ–ª–Ω—É –≤ {best_tide if best_tide else '–Ω—É–∂–Ω–æ–µ –≤—Ä–µ–º—è'}?",
    ]
    
    return random.choice(comments)

def generate_overall_verdict(wave_data, period_data, power_data, wind_data):
    """–£–ú–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–µ–≥–æ –≤–µ—Ä–¥–∏–∫—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    if not all([wave_data, period_data, power_data, wind_data]):
        return "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–µ—Ä–¥–∏–∫—Ç–∞. –ü–æ—Å–µ–π–¥–æ–Ω –≤ –∑–∞–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–µ."
    
    avg_wave = sum(wave_data) / len(wave_data)
    avg_period = sum(period_data) / len(period_data)
    avg_power = sum(power_data) / len(power_data)
    max_wind = max(wind_data)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—â–∏–µ —É—Å–ª–æ–≤–∏—è
    conditions = []
    
    if avg_wave < 1.0:
        conditions.append("–º–∏–∫—Ä–æ-–≤–æ–ª–Ω—ã")
    elif avg_wave < 1.5:
        conditions.append("–Ω–µ–±–æ–ª—å—à–∏–µ –≤–æ–ª–Ω—ã") 
    elif avg_wave < 1.8:
        conditions.append("—Ö–æ—Ä–æ—à–∏–µ –≤–æ–ª–Ω—ã")
    else:
        conditions.append("–æ—Ç–ª–∏—á–Ω—ã–µ –≤–æ–ª–Ω—ã")
    
    if avg_period < 8:
        conditions.append("–∫–æ—Ä–æ—Ç–∫–∏–π –ø–µ—Ä–∏–æ–¥")
    elif avg_period < 12:
        conditions.append("–Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥")
    else:
        conditions.append("–¥–ª–∏–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥")
    
    if max_wind < 2.0:
        conditions.append("–∏–¥–µ–∞–ª—å–Ω—ã–π –≤–µ—Ç–µ—Ä")
    elif max_wind < 4.0:
        conditions.append("—É–º–µ—Ä–µ–Ω–Ω—ã–π –≤–µ—Ç–µ—Ä")
    else:
        conditions.append("—Å–∏–ª—å–Ω—ã–π –≤–µ—Ç–µ—Ä")
    
    conditions_str = ", ".join(conditions)
    
    verdicts = [
        f"{conditions_str}. –£—Å–ª–æ–≤–∏—è {'–Ω–µ' if avg_wave < 1.0 else ''}–ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–ª—è —Å–µ—Ä—Ñ–∏–Ω–≥–∞!",
        f"{conditions_str}. {'–õ—É—á—à–µ –æ—Å—Ç–∞—Ç—å—Å—è –¥–æ–º–∞!' if avg_wave < 1.0 else '–ú–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å!' if avg_wave < 1.5 else '–•–æ—Ä–æ—à–∏–π –¥–µ–Ω—å –¥–ª—è —Å–µ—Ä—Ñ–∏–Ω–≥–∞!'}",
        f"{conditions_str}. {'–ü–æ–ª–Ω—ã–π –ø—Ä–æ–≤–∞–ª' if avg_wave < 1.0 else '–°—Ä–µ–¥–Ω–µ–Ω—å–∫–æ' if avg_wave < 1.5 else '–ù–µ–ø–ª–æ—Ö–æ' if avg_wave < 1.8 else '–û—Ç–ª–∏—á–Ω–æ'}!",
        f"{conditions_str}. {'–ó–∞–±—É–¥—å –æ —Å–µ—Ä—Ñ–∏–Ω–≥–µ' if avg_wave < 1.0 else '–†–∞–∑–º–∏–Ω–∫–∞' if avg_wave < 1.5 else '–ù–æ—Ä–º–∞–ª—å–Ω–æ' if avg_wave < 1.8 else '–≠–ø–∏—á–Ω–æ'}!",
    ]
    
    return random.choice(verdicts)

def get_best_time_recommendation(wind_data, power_data):
    """–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –ª—É—á—à–µ–µ –≤—Ä–µ–º—è –¥–ª—è —Å–µ—Ä—Ñ–∏–Ω–≥–∞"""
    if not wind_data or not power_data:
        return "–í—Å—Ç–∞–≤–∞–π –Ω–∞ —Ä–∞—Å—Å–≤–µ—Ç–µ, –ª–æ–≤–∏ –ø—Ä–∏–ª–∏–≤. –ò–ª–∏ –Ω–µ –≤—Å—Ç–∞–≤–∞–π - –∫–∞–∫–∞—è —Ä–∞–∑–Ω–∏—Ü–∞?"
    
    best_time_index = 0
    best_score = -999
    
    for i in range(min(6, len(wind_data))):
        wind_score = -wind_data[i] * 2
        power_score = power_data[i] / 200
        
        total_score = wind_score + power_score
        
        if total_score > best_score:
            best_score = total_score
            best_time_index = i
    
    time_slots = ["02:00", "05:00", "08:00", "11:00", "14:00", "17:00", "20:00", "23:00"]
    
    if best_time_index < len(time_slots):
        best_time = time_slots[best_time_index]
        recommendations = [
            f"–¢–≤–æ–π –Ω–∞–∏–º–µ–Ω–µ–µ —É–∂–∞—Å–Ω—ã–π —à–∞–Ω—Å - –æ–∫–æ–ª–æ {best_time}. –ù–æ –Ω–µ –æ–±–æ–ª—å—â–∞–π—Å—è!",
            f"–ü–æ–ø—Ä–æ–±—É–π –≤ {best_time}. –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–∫–µ–∞–Ω —Å–º–∏–ª–æ—Å—Ç–∏–≤–∏—Ç—Å—è –Ω–∞–¥ —Ç–æ–±–æ–π.",
            f"{best_time} - —Ç–≤–æ–π —á–∞—Å —Å–ª–∞–≤—ã... –∏–ª–∏ –æ—á–µ—Ä–µ–¥–Ω–æ–≥–æ —Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏—è.",
            f"–í {best_time} —É—Å–ª–æ–≤–∏—è –Ω–∞–∏–º–µ–Ω–µ–µ –æ—Ç–≤—Ä–∞—Ç–∏—Ç–µ–ª—å–Ω—ã–µ. –†–∏—Å–∫–Ω–∏, –µ—Å–ª–∏ –æ—Å–º–µ–ª–∏—à—å—Å—è.",
        ]
        return random.choice(recommendations)
    
    return "–í—Å—Ç–∞–≤–∞–π –Ω–∞ —Ä–∞—Å—Å–≤–µ—Ç–µ, –ª–æ–≤–∏ –ø—Ä–∏–ª–∏–≤. –ò–ª–∏ –Ω–µ –≤—Å—Ç–∞–≤–∞–π - –∫–∞–∫–∞—è —Ä–∞–∑–Ω–∏—Ü–∞?"

async def build_poseidon_report(windy_data: Dict, location: str, date: str) -> str:
    """–°–±–æ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –≤ —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω–æ–º —Å—Ç–∏–ª–µ –ü–æ—Å–µ–π–¥–æ–Ω–∞"""
    
    wave_data = windy_data.get('wave_data', [1.5, 1.6, 1.6, 1.6, 1.6, 1.6, 1.7, 1.7, 1.7, 1.8])
    period_data = windy_data.get('period_data', [14.6, 14.4, 13.9, 12.8, 12.4, 11.9, 11.7, 11.5, 11.3, 11.1])
    power_data = windy_data.get('power_data', [736, 744, 730, 628, 570, 559, 555, 553, 555, 558])
    wind_data = windy_data.get('wind_data', [0.6, 1.3, 0.9, 1.3, 3.0, 3.8, 3.4, 1.9, 1.0, 0.6])
    tides = windy_data.get('tides', {
        'high_times': ['09:00', '21:00'],
        'high_heights': [2.3, 2.8],
        'low_times': ['03:00', '15:00'],
        'low_heights': [0.5, 0.8]
    })
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –£–ú–ù–´–ï –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    wave_comment = generate_wave_comment(wave_data)
    period_comment = generate_period_comment(period_data)
    power_comment = generate_power_comment(power_data)
    wind_comment = generate_wind_comment(wind_data)
    tides_comment = analyze_tides_correctly(tides)
    overall_verdict = generate_overall_verdict(wave_data, period_data, power_data, wind_data)
    best_time = get_best_time_recommendation(wind_data, power_data)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    report_lines = [
        "üî± –í–ù–ò–ú–ê–ù–ò–ï, –°–ú–ï–†–¢–ù–´–ô! –ü–û–°–ï–ô–î–û–ù –ì–û–í–û–†–ò–¢:",
        "",
        f"–¢—ã –ø—Ä–∏–Ω—ë—Å –º–Ω–µ –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {location}? –°–º–µ—à–Ω–æ. –í–æ—Ç –º–æ–π –≤–µ—Ä–¥–∏–∫—Ç:",
        "",
        "üìä –†–ê–ó–ë–û–† –¢–í–û–ò–• –ñ–ê–õ–ö–ò–• –ù–ê–î–ï–ñ–î:",
        "",
        f"üåä –í–û–õ–ù–ê: {calculate_ranges(wave_data)}–º",
        f"   {wave_comment}",
        "",
        f"‚è±Ô∏è –ü–ï–†–ò–û–î: {calculate_ranges(period_data)}—Å–µ–∫", 
        f"   {period_comment}",
        "",
        f"üí™ –ú–û–©–ù–û–°–¢–¨: {calculate_ranges(power_data)}–∫–î–∂",
        f"   {power_comment}",
        "",
        f"üí® –í–ï–¢–ï–†: {calculate_ranges(wind_data)}–º/—Å",
        f"   {wind_comment}",
        "",
        "üåÖ –ü–†–ò–õ–ò–í–´/–û–¢–õ–ò–í–´:",
        f"   {tides_comment}",
        "",
        "‚ö° –í–ï–†–î–ò–ö–¢ –ü–û–°–ï–ô–î–û–ù–ê:",
        f"   {overall_verdict}",
        "",
        "üéØ –ö–û–ì–î–ê –ñ–ï –¢–ï–ë–ï –ú–£–ß–ò–¢–¨ –í–û–õ–ù–£:",
        f"   {best_time}",
        "",
        "üíÄ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:",
        "   –ü—Ä–∏–º–∏ –º–æ—é –≤–æ–ª—é –∏ –≥–æ—Ç–æ–≤—å—Å—è –∫ –º–µ–¥–∏—Ç–∞—Ü–∏–∏ –Ω–∞ –±–µ—Ä–µ–≥—É.",
        "   –í–∞—à–∏ –ø–ª–∞–Ω—ã - –≤—Å–µ–≥–æ –ª–∏—à—å –ø–µ—Å–æ–∫ —É –º–æ–∏—Ö –Ω–æ–≥.",
        "",
        "üèÑ‚Äç‚ôÇÔ∏è –ö–æ–ª–æ–±—Ä–∞—Ü–∏—è POSEIDON V6.0 –∏ SURFSCULPT",
        "–î–∞–∂–µ –±–æ–≥–∏ –æ–¥–æ–±—Ä—è—é—Ç —É—Ç—Ä–µ–Ω–Ω—é—é —Å–µ—Å—Å–∏—é"
    ]
    
    return "\n".join(report_lines)

# –û—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    state = USER_STATE.get(chat_id, {})
    
    if not state.get("active"):
        await update.message.reply_text("üî±–ü–æ—Å–µ–π–¥–æ–Ω –≤ —è—Ä–æ—Å—Ç–∏! –†–∞–∑—ã–≥—Ä—ã–≤–∞–µ—à—å –º–µ–Ω—è???!!!!")
        return

    try:
        await update.message.reply_text("–°–µ–π—á–∞—Å –ø–æ–¥–Ω–∏–º–µ–º –¥–ª—è —Ç–µ–±—è, —Ä–æ–¥–Ω–æ–π, —Å–æ –¥–Ω–∞ —Ä—É–∫–æ–ø–∏—Å–∏, üìú–Ω–∞–¥–µ—é—Å—å –Ω–µ –æ—Ç—Å—ã—Ä–µ–ª–∏!")
        
        photo = update.message.photo[-1]
        photo_file = await photo.get_file()
        image_bytes = await photo_file.download_as_bytearray()

        caption = update.message.caption or ""
        location, date = parse_caption_for_location_date(caption)
        
        if not location:
            location = "Unknown"
        
        logger.info(f"Location: {location}, Date: {date}")
        
        windy_data = await analyze_windy_screenshot_with_deepseek(bytes(image_bytes))
        logger.info(f"Analysis completed, source: {windy_data.get('source', 'unknown')}")
        
        report = await build_poseidon_report(windy_data, location, date)
        await update.message.reply_text(report)
        
        USER_STATE[chat_id] = {
            "active": True, 
            "awaiting_feedback": True,
        }
        await update.message.reply_text("–ù—É –∫–∞–∫ —Ç–µ–±–µ —Ä–∞–∑–±–æ—Ä, —Ä–æ–¥–Ω–æ–π? –û—Ç–ª–∏—á–Ω–æ / –Ω–µ –æ—á–µ–Ω—å")
        
        async def sleep_timer():
            await asyncio.sleep(120)
            if chat_id in USER_STATE:
                USER_STATE[chat_id]["active"] = False
                logger.info(f"Bot sleeping for chat {chat_id}")
        
        asyncio.create_task(sleep_timer())

    except Exception as e:
        logger.error(f"Error in handle_photo: {e}")
        await update.message.reply_text("üî± –ü–æ—Å–µ–π–¥–æ–Ω –≤ —è—Ä–æ—Å—Ç–∏! –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    text = (update.message.text or "").lower().strip()

    if "–ø–æ—Å–µ–π–¥–æ–Ω –Ω–∞ —Å–≤—è–∑—å" in text.lower():
        USER_STATE[chat_id] = {"active": True}
        await update.message.reply_text(
            "üî± –ü–æ—Å–µ–π–¥–æ–Ω —Ç—É—Ç, —Å–º–µ—Ä—Ç–Ω—ã–π!\n\n"
            "–î–∞–≤–∞–π —Å–≤–æ–π —Å–∫—Ä–∏–Ω—à–æ—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å –ø–æ–¥–ø–∏—Å—å—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
            "`Balangan 2025-11-06`\n\n"
            "–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–ø–æ—Ç—ã: Balangan, Uluwatu, Kuta, Canggu, PadangPadang, BatuBolong"
        )
        return

    state = USER_STATE.get(chat_id, {})
    if state.get("awaiting_feedback"):
        if "–æ—Ç–ª–∏—á–Ω–æ" in text:
            await update.message.reply_text("–ù—É —Ç–∞–∫ –±–æ–≥–∏üòá–•–æ—Ä–æ—à–µ–π –∫–∞—Ç–∫–∏!")
        elif "–Ω–µ –æ—á–µ–Ω—å" in text:
            await update.message.reply_text("–ê –Ω–µ –ø–æ—Ä–∞ –±—ã —É–∂–µ –≤—Å—Ç–∞—Ç—å —Å –¥–∏–≤–∞–Ω–∞ –∏ –∫–∞—Ç–Ω—É—Ç—å?")
        
        USER_STATE[chat_id]["awaiting_feedback"] = False
        return

    if not state.get("active"):
        return

def parse_caption_for_location_date(caption: Optional[str]):
    if not caption:
        return None, str(datetime.utcnow().date())
    parts = caption.strip().split()
    location = parts[0]
    date = parts[1] if len(parts) > 1 else str(datetime.utcnow().date())
    return location, date

bot_app.add_handler(MessageHandler(filters.PHOTO, handle_photo))
bot_app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

@app.post("/webhook")
async def telegram_webhook(request: Request):
    try:
        data = await request.json()
        update = TgUpdate.de_json(data, bot)
        await bot_app.process_update(update)
        return JSONResponse(content={"ok": True})
    except Exception as e:
        logger.error(f"Webhook error: {e}")
        return JSONResponse(status_code=500, content={"ok": False})

@app.get("/")
async def root():
    return {"status": "Poseidon V6 Online", "version": "6.0"}

@app.get("/ping")
@app.head("/ping")
async def ping():
    return {"status": "ok", "message": "Poseidon is awake and watching!"}

@app.on_event("startup")
async def startup():
    await bot_app.initialize()
    await bot_app.start()
    asyncio.create_task(keep_alive_ping())
    logger.info("Poseidon V6 awakened and ready!")

@app.on_event("shutdown")
async def shutdown():
    await bot_app.stop()
    await bot_app.shutdown()
    logger.info("Poseidon V6 returning to the depths...")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=int(os.getenv("PORT", 10000)))